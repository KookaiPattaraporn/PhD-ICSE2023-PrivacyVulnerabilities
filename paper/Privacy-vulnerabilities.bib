Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{rep-pkg-privul,
author = {Sangaroonsilp, Pattaraporn and Dam, Hoa Khanh and Ghose, Aditya},
title = {{Replication Package}},
url = {https://figshare.com/articles/conference_contribution/icse2023-paper908-replication-pkg/21922731},
year = {2022}
}
@inproceedings{McPherson2015,
abstract = {Augmented reality (AR) browsers are an emerging category of mobile applications that add interactive virtual objects to the user's view of the physical world. This paper gives the first system-level evaluation of their security and privacy properties. We start by analyzing the functional requirements that AR browsers must support in order to present AR content. We then investigate the security architecture of Junaio, Layar, andWikitude browsers, which are running today on over 30 million mobile devices, and identify new categories of security and privacy vulnerabilities unique to AR browsers. Finally, we provide the first engineering guidelines for securely implementing AR functionality.},
author = {McPherson, Richard and Jana, Suman and Shmatikov, Vitaly},
booktitle = {WWW 2015 - Proceedings of the 24th International Conference on World Wide Web},
pages = {743--753},
title = {{No escape from reality: Security and privacy of augmented reality browsers}},
year = {2015}
}
@misc{OAIC2021,
author = {{Office of the Australian Information Commissioner}},
title = {{Notifiable data breaches statistics}},
url = {https://www.oaic.gov.au/privacy/notifiable-data-breaches/notifiable-data-breaches-statistics/},
urldate = {2021-08-25},
year = {2021}
}
@article{Liu2020a,
abstract = {Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML)-based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for ML and the other is class imbalance between vulnerable code and nonvulnerable code. To overcome these challenges, this article develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with bidirectional long short-term memory to learn invariant and discriminative code representations from labeled vulnerable and nonvulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth dataset that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement is 15{\%} in terms of F-measure.},
author = {Liu, Shigang and Lin, Guanjun and Han, Qing Long and Wen, Sheng and Zhang, Jun and Xiang, Yang},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - DeepBalance Deep-Learning and Fuzzy Oversampling for Vulnerability Detection.pdf:pdf},
journal = {IEEE Transactions on Fuzzy Systems},
keywords = {Software vulnerability detection,class imbalance,deep learning (DL),feature learning,machine learning (ML)},
number = {7},
pages = {1329--1343},
title = {{DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection}},
volume = {28},
year = {2020}
}
@misc{US1974,
author = {{U.S. Department of Justice}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/U.S. Department of Justice - 1974 - The Privacy Act of 1974.pdf:pdf},
title = {{The Privacy Act of 1974}},
year = {1974}
}
@techreport{OfficeJournaloftheEuropeanUnion;2016,
author = {{Office Journal of the European Union}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Office Journal of the European Union - 2016 - Regulation (EU) 2016679 of the European Parliament and of the Council of 27 April 2016 on.pdf:pdf},
keywords = {GDPR},
mendeley-tags = {GDPR},
pages = {1--88},
title = {{General Data Protection Regulation (GDPR)}},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679},
year = {2016}
}
@book{Neisse2016,
abstract = {{\textcopyright} 2017 by Taylor {\&} Francis Group, LLC. Mobile platforms, such as Android, iOS, and Windows, are gaining more and more relevance within end users' applications, thanks to their usability, flexibility, and low cost. As a result, mobile Internet traffic is about to overwhelm landline traffic. Mobile platforms do not only provide end users with services similar to legacy computers but also extend their experiences exploiting the additional hardware features (e.g., sensors) incorporated in the mobile device, without the need of supplementary devices. Moreover, mobile devices are becoming the sources and repositories of sensitive information, from running performances to positioning data, from travel information to friendship preferences, from personal photos to financial data, and so on. Data loss, modification, or exposure that a mobile device might face, on one hand, could directly impact end users' safety and privacy, but, on the other hand, they could seriously damage the trust in the rising mobile economy. A typical example of these threats could be the case in which a mobile application that monitors some end user's body parameters is exploited by an adversary to gain access to sensitive data and infer the end user's health status. The possible damages caused by this data breach can impact both the psychological and physical spheres of an end user. Although these problems and flaws already existed in the traditional information and communication technologies (ICT) systems, their magnitude increased exponentially in the case of mobile devices due to their stronger link with the owner. Indeed, as already mentioned, mobile devices embed several sensors and functionalities capable of collecting a huge amount of sensitive information. As a consequence, any vulnerability in the host platform can have a high impact on end user's privacy and security. In this chapter, we analyze the different characteristics of the Android platform that can be manipulated and exploited by a malicious app to gain access to an end users' private data. Android, the dominant operating system (OS) in the mobile world, is indeed taken as a use case to illustrate threats, which, in the reality, affect the majority of mobile OSs. Moreover, by elaborating on these security flaws and misconfigurations, we describe different threat examples that influence end users' privacy and anonymity in a risk assessment fashion. Furthermore, this chapter reviews the different existing solutions that can be employed to mitigate the described threats and to empower end users in regaining control on their sensitive information and on the behavior of the mobile applications installed in their mobile devices},
author = {Neisse, R. and Geneiatakis, D. and Steri, G. and Kambourakis, G. and Fovino, I.N. and Satta, R.},
booktitle = {Protecting Mobile Networks and Devices: Challenges and Solutions},
pages = {67--92},
title = {{Dealing with user privacy in mobile apps: Issues and mitigation}},
year = {2016}
}
@inproceedings{Chang2011,
abstract = {Understanding vulnerability trends is a key component of the risk management process. The focus of this research is to analyze the trends of Common Vulnerabilities and Exposures (CVE) from the National Vulnerability Database (NVD) from 2007 to 2010. We extracted 22,521 CVEs through the four years, also collected their Common Vulnerability Scoring System (CVSS) scores from the NVD; then we analyzed the overall frequency, severity, and CVSS base metrics trends. Our finding shows that the frequency of all vulnerabilities decreased by 28{\%} from 2007 to 2010; also, the percentage of high severity incidents decreased for that period. Over 80{\%} of the total vulnerabilities were exploitable by network access without authentication. We further studied the trends of the select fifteen (15) vulnerability types which contain 18,427 vulnerabilities by analyzing their changes in frequency, severity, and CVSS base metrics. This research findings can help information security professionals focus their efforts in preventing and mitigating the impact of the attacks, and influence the development of security strategies developed by IS professionals as well. {\textcopyright} 2011 IEEE.},
author = {Chang, Yung Yu and Zavarsky, Pavol and Ruhl, Ron and Lindskog, Dale},
booktitle = {Proceedings - 2011 IEEE International Conference on Privacy, Security, Risk and Trust and IEEE International Conference on Social Computing, PASSAT/SocialCom 2011},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2011 - Trend analysis of the CVE for software vulnerability management.pdf:pdf},
keywords = {CVE,CVSS version2,NVD,Vulnerability trend,Vulnerability type},
pages = {1290--1293},
title = {{Trend analysis of the CVE for software vulnerability management}},
year = {2011}
}
@article{Deng2011,
abstract = {Ready or not, the digitalization of information has come, and privacy is standing out there, possibly at stake. Although digital privacy is an identified priority in our society, few systematic, effective methodologies exist that deal with privacy threats thoroughly. This paper presents a comprehensive framework to model privacy threats in software-based systems. First, this work provides a systematic methodology to model privacy-specific threats. Analogous to STRIDE, an information flow-oriented model of the system is leveraged to guide the analysis and to provide broad coverage. The methodology instructs the analyst on what issues should be investigated, and where in the model those issues could emerge. This is achieved by (i) defining a list of privacy threat types and (ii) providing the mappings between threat types and the elements in the system model. Second, this work provides an extensive catalog of privacy-specific threat tree patterns that can be used to detail the threat analysis outlined above. Finally, this work provides the means to map the existing privacy-enhancing technologies (PETs) to the identified privacy threats. Therefore, the selection of sound privacy countermeasures is simplified. {\textcopyright} 2010 Springer-Verlag London Limited.},
author = {Deng, Mina and Wuyts, Kim and Scandariato, Riccardo and Preneel, Bart and Joosen, Wouter},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng et al. - 2011 - A privacy threat analysis framework Supporting the elicitation and fulfillment of privacy requirements.pdf:pdf},
journal = {Requirements Engineering},
keywords = {Privacy,Requirements,Secure software engineering,Threat modeling},
number = {1},
pages = {3--32},
title = {{A privacy threat analysis framework: Supporting the elicitation and fulfillment of privacy requirements}},
volume = {16},
year = {2011}
}
@article{Drosatos2014a,
abstract = {This paper presents a privacy-preserving system for participatory sensing, which relies on cryptographic techniques and distributed computations in the cloud. Each individual user is represented by a personal software agent, deployed in the cloud, where it collaborates on distributed computations without loss of privacy, including with respect to the cloud service providers. We present a generic system architecture involving a cryptographic protocol based on a homomorphic encryption scheme for aggregating sensing data into maps, and demonstrate security in the Honest-But-Curious model both for the users and the cloud service providers. We validate our system in the context of NoiseTube, a participatory sensing framework for noise pollution, presenting experiments with real and artificially generated data sets, and a demo on a heterogeneous set of commercial cloud providers. To the best of our knowledge our system is the first operational privacy-preserving system for participatory sensing. While our validation pertains to the noise domain, the approach used is applicable in any crowd-sourcing application relying on location-based contributions of citizens where maps are produced by aggregating data - also beyond the domain of environmental monitoring. {\textcopyright} 2014 Elsevier Inc.},
author = {Drosatos, George and Efraimidis, Pavlos S. and Athanasiadis, Ioannis N. and Stevens, Matthias and D'Hondt, Ellie},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Drosatos et al. - 2014 - Privacy-preserving computation of participatory noise maps in the cloud.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Cloud computing,Participatory sensing,Privacy-preserving computation},
month = {jun},
number = {1},
pages = {170--183},
publisher = {Elsevier},
title = {{Privacy-preserving computation of participatory noise maps in the cloud}},
volume = {92},
year = {2014}
}
@inproceedings{BilogrevicIgor2011,
abstract = {Mobile devices are increasingly being used to store and manage users' personal information, as well as to access popular third-party context-based services. Very often, these applications need to determine common availabilities among a set of user schedules, in order to allow colleagues, business partners and people to meet. The privacy of the scheduling operation is paramount to the success of such applications, as often users do not want to share their personal schedule details with other users or third-parties. In this paper, we propose practical and privacy-preserving solutions for mobile devices to the server-based scheduling problem. Our three novel algorithms take advantage of the homomorphic properties of well-known cryptosystems in order to privately and efficiently compute common user availabilities. We also formally outline the privacy requirements in such scheduling applications and we implement our solutions on real mobile devices. The experimental measurements and analytical results show that the proposed solutions not only satisfy the privacy properties but also fare better, in regard to computation and communication efficiency, compared to other well-known solutions. Finally, we assess the utility and expectations, in terms of privacy and usability, of the proposed solutions by means of a targeted survey and user-study of mobile-phone users. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
author = {Bilogrevic, Igor and Jadliwala, Murtuza and Kumar, Praveen and Walia, Sudeep Singh and Hubaux, Jean Pierre and Aad, Imad and Niemi, Valtteri},
booktitle = {Journal of Systems and Software},
doi = {10.1016/j.jss.2011.04.027},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilogrevic et al. - 2011 - Meetings through the cloud Privacy-preserving scheduling on mobile devices.pdf:pdf},
issn = {01641212},
keywords = {Activity scheduling,Client-server architecture,Homomorphic encryption,Mobile devices},
number = {11},
pages = {1910--1927},
title = {{Meetings through the cloud: Privacy-preserving scheduling on mobile devices}},
volume = {84},
year = {2011}
}
@inproceedings{Calciati,
abstract = {The mobile app market is evolving at a very fast pace. In order to stay in the market and fulfill user's growing demands, developers have to continuously update their apps either to fix issues or to add new features. Users and market managers may have a hard time understanding what really changed in a new release though, and therefore may not make an informative guess of whether updating the app is recommendable, or whether it may pose new security and privacy threats for the user. We propose a ready-to-use framework to analyze the evolution of Android apps. Our framework extracts and visualizes various information - -such as how an app uses sensitive data, which third-party libraries it relies on, which URLs it connects to, etc. - - and combines it to create a comprehensive report on how the app evolved. Besides, we present the results of an empirical study on 235 applications with at least 50 releases using our framework. Our analysis reveals that Android apps tend to have more leaks of sensitive data over time, and that the majority of API calls relative to dangerous permissions are added to the code in releases posterior to the one where the corresponding permission was requested.},
author = {Calciati, Paolo and Kuznetsov, Konstantin and Bai, Xue and Gorla, Alessandra},
booktitle = {Proceedings - International Conference on Software Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Calciati et al. - 2018 - What did really change with the new release of the app.pdf:pdf},
keywords = {Android,app evolution,behavior change},
pages = {142--152},
title = {{What did really change with the new release of the app?}},
volume = {18},
year = {2018}
}
@misc{NIST2016,
abstract = {The NVD is the U.S. government repository of standards based vulnerability management data represented using the Security Content Automation Protocol (SCAP). This data enables automation of vulnerability management, security measurement, and compliance. The NVD includes databases of security checklist references, security-related software flaws, misconfigurations, product names, and impact metrics.},
author = {NIST},
booktitle = {National Vulnerability Database},
title = {{NVD - Home}},
url = {https://nvd.nist.gov/},
urldate = {2021-08-04},
year = {2016}
}
@inproceedings{Jana2013,
abstract = {Perceptual, "context-aware" applications that observe their environment and interact with users via cameras and other sensors are becoming ubiquitous on personal computers, mobile phones, gaming platforms, household robots, and augmented-reality devices. This raises new privacy risks. We describe the design and implementation of DARKLY, a practical privacy protection system for the increasingly common scenario where an untrusted, third-party perceptual application is running on a trusted device. DARKLY is integrated with OpenCV, a popular computer vision library used by such applications to access visual inputs. It deploys multiple privacy protection mechanisms, including access control, algorithmic privacy transforms, and user audit. We evaluate DARKLY on 20 perceptual applications that perform diverse tasks such as image recognition, object tracking, security surveillance, and face detection. These applications run on DARKLY unmodified or with very few modifications and minimal performance overheads vs. native OpenCV. In most cases, privacy enforcement does not reduce the applications' functionality or accuracy. For the rest, we quantify the tradeoff between privacy and utility and demonstrate that utility remains acceptable even with strong privacy protection. {\textcopyright} 2013 IEEE.},
author = {Jana, Suman and Narayanan, Arvind and Shmatikov, Vitaly},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Computer vision,Privacy},
pages = {349--363},
title = {{A scanner darkly: Protecting user privacy from perceptual applications}},
year = {2013}
}
@inproceedings{Chernis,
abstract = {Software vulnerabilities are a primary concern in the IT security industry, as malicious hackers who discover these vulnerabilities can often exploit them for nefarious purposes. However, complex programs, particularly those written in a relatively low-level language like C, are difficult to fully scan for bugs, even when both manual and automated techniques are used. Since analyzing code and making sure it is securely written is proven to be a non-trivial task, both static analysis and dynamic analysis techniques have been heavily investigated, and this work focuses on the former. The contribution of this paper is a demonstration of how it is possible to catch a large percentage of bugs by extracting text features from functions in C source code and analyzing them with a machine learning classifier. Relatively simple features (character count, character diversity, entropy, maximum nesting depth, arrow count, “if" count, “if" complexity, “while" count, and “for" count) were extracted from these functions, and so were complex features (character n-grams, word n-grams, and suffix trees). The simple features performed unexpectedly better compared to the complex features (74{\%} accuracy compared to 69{\%} accuracy).},
author = {Chernis, Boris and Verma, Rakesh},
booktitle = {IWSPA 2018 - Proceedings of the 4th ACM International Workshop on Security and Privacy Analytics, Co-located with CODASPY 2018},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chernis, Verma - 2018 - Machine learning methods for software vulnerability detection.pdf:pdf},
keywords = {Buffer overflow,Machine learning,N-grams,Software metrics,Static analysis,Suffix trees,Vulnerability detection},
pages = {31--39},
title = {{Machine learning methods for software vulnerability detection}},
volume = {2018-Janua},
year = {2018}
}
@article{Anh2014,
abstract = {The proliferation of mobile devices coupled with Internet access is generating a tremendous amount of highly personal and sensitive data. Applications such as location-based services and quantified self harness such data to bring meaningful context to users' behavior. As social applications are becoming prevalent, there is a trend for users to share their mobile data the nature of online social networking poses new challenges for controlling access to private data, as compared to traditional enterprise systems. First, the user may have a large number of friends, each associated with a unique access policy. Second, the access control policies must be dynamic and fine-grained, i.e they are content-based, as opposed to all-or-nothing. In this paper, we investigate the challenges in sharing of mobile data in social applications. We design and evaluate a middleware running on Google App Engine, named Mosco, that manages and facilitates sharing of mobile data in a privacy-preserving manner. We use Mosco to develop a location sharing and a health monitoring application. Mosco helps shorten the development process. Finally, we perform benchmarking experiments with Mosco, the results of which indicate small overhead and high scalability. {\textcopyright} 2013 Elsevier Inc.},
author = {{Tuan Anh}, Dinh Tien and Ganjoo, Milind and Braghin, Stefano and Datta, Anwitaman},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuan Anh et al. - 2014 - Mosco A privacy-aware middleware for mobile social computing.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Fine-grained access control,Google App Engine,Social computing,XACML},
number = {1},
pages = {20--31},
publisher = {Elsevier Inc.},
title = {{Mosco: A privacy-aware middleware for mobile social computing}},
url = {https://www.infona.pl//resource/bwmeta1.element.elsevier-ef19f2ed-d759-30fe-b942-4e347e412634},
volume = {92},
year = {2014}
}
@article{MahinderjitSingh2016,
abstract = {Wearable Technology also called wearable gadget , is acategory of technology devices with low processing capabilities that can be worn by a user with the aim to provide information and ease of access to the master devices its pairing with . Such examples are Google Glass and Smart watch . The impact of wearable technology becomes significant when people start their invention in wearable computing , where their mobile devices become one of the computation sources . However , wearable technology is not mature yet in term of device security and privacy acceptance of the public . There exists some security weakness that prompts such wearable devices vulnerable to attack . One of the critical attack on wearable technology is authentication issue . The low processing due to less computing power of wearable device causethe developer ' s inability to equip some complicated security mechanisms and algorithm on the device . In this study , an overview of security and privacy vulnerabilities on wearable devices is presented .},
author = {Ching, Ke Wan and Singh, Manmeet Mahinderjit},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ching, Singh - 2016 - Wearable Technology Devices Security and Privacy Vulnerability Analysis.pdf:pdf},
journal = {International Journal of Network Security {\&} Its Applications},
number = {3},
pages = {19--30},
title = {{Wearable Technology Devices Security and Privacy Vulnerability Analysis}},
volume = {8},
year = {2016}
}
@misc{NIST2021,
author = {NIST},
booktitle = {National Vulnerability Database},
title = {{NVD - Categories}},
url = {https://nvd.nist.gov/vuln/categories},
urldate = {2021-08-23},
year = {2021}
}
@inproceedings{Barman2015,
abstract = {Recently, several solutions have been proposed to address the complex challenge of protecting individuals' genetic data during personalized medicine tests. In this short paper, we analyze different privacy threats and propose simple countermeasures for the generic architecture mainly used in the literature. In particular, we present and evaluate a new practical solution against a critical attack of a malicious medical center trying to actively infer raw genetic information of patients.},
author = {Barman, Ludovic and Elgraini, Mohammed Taha and Raisaro, Jean Louis and Hubaux, Jean Pierre and Ayday, Erman},
booktitle = {Proceedings - 2015 IEEE Security and Privacy Workshops, SPW 2015},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barman et al. - 2015 - Privacy threats and practical solutions for genetic risk tests.pdf:pdf},
keywords = {Cryptography,Genomic privacy,Risk tests},
pages = {27--31},
title = {{Privacy threats and practical solutions for genetic risk tests}},
year = {2015}
}
@misc{CVE,
abstract = {Common Vulnerabilities and Exposures (CVE{\textregistered}) is a list of common identifiers for publicly known cybersecurity vulnerabilities. Use of CVE Entries, which are assigned by CVE Numbering Authorities (CNAs) from around the world, ensures confidence among parties when used to discuss or share information about a unique software or firmware vulnerability, provides a baseline for tool evaluation, and enables data exchange for cybersecurity automation.},
author = {{The MITRE Corporation}},
title = {{About CVE}},
url = {https://cve.mitre.org/about/index.html},
urldate = {2021-07-20},
year = {2021}
}
@inproceedings{Bertolino2018,
abstract = {Background In Software Engineering (SE), conference publications have high importance both in effective communication and in academic careers. Researchers actively discuss how a paper should be organized to be accepted in mainstream conferences. Aiming This work tackles the problem of generalizing and characterizing the type of papers accepted at SE conferences. Method The paper offers a new perspective in the analysis of SE literature: a categorization scheme for SE papers is obtained by merging, extending and revising related proposals from a few existing studies. The categorization scheme is used to classify the papers accepted at three top-tier SE conferences during five years (2012–2016). Results While a broader experience is certainly needed for validation and fine-tuning, preliminary outcomes can be observed relative to what problems and topics are addressed, what types of contributions are presented and how they are validated. Conclusions The results provide insights to paper writers, paper reviewers and conference organizers in focusing their future efforts, without any intent to provide judgments or authoritative guidelines.},
author = {Bertolino, Antonia and Calabr{\`{o}}, Antonello and Lonetti, Francesca and Marchetti, Eda and Miranda, Breno},
booktitle = {Journal of Systems and Software},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertolino et al. - 2018 - A categorization scheme for software engineering conference papers and its application.pdf:pdf},
keywords = {Conference,Paper categorization,Paper type,Research contribution,Research problem,Validation},
pages = {114--129},
title = {{A categorization scheme for software engineering conference papers and its application}},
volume = {137},
year = {2018}
}
@article{Breaux2008,
abstract = {Information practices that use personal, financial and health-related information are governed by U.S. laws and regulations to prevent unauthorized use and disclosure. To ensure compliance under the law, the security and privacy requirements of relevant software systems must be properly aligned with these regulations. However, these regulations describe stakeholder rules, called rights and obligations, in complex and sometimes ambiguous legal language. These "rules" are often precursors to software requirements that must undergo considerable refinement and analysis before they are implementable. To support the software engineering effort to derive security requirements from regulations, we present a methodology to extract access rights and obligations directly from regulation texts. The methodology provides statement-level coverage for an entire regulatory document to consistently identify and infer six types of data access constraints, handle complex cross-references, resolve ambiguities, and assign required priorities between access rights and obligations to avoid unlawful information disclosures. We present results from applying this methodology to the entire regulation text of the U.S. Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule. {\textcopyright} 2008 IEEE.},
author = {Breaux, Travis D. and Ant{\'{o}}n, Annie I.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breaux, Ant{\'{o}}n - 2008 - Analyzing regulatory rules for privacy and security requirements.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {Accountability,Compliance,Information and privacy,Laws and regulations,Requirements engineering},
number = {1},
pages = {5--20},
title = {{Analyzing regulatory rules for privacy and security requirements}},
volume = {34},
year = {2008}
}
@misc{TheOWASPFoundation,
abstract = {OWASP Top 10 Privacy Risks on the main website for The OWASP Foundation. OWASP is a nonprofit foundation that works to improve the security of software.},
author = {{The OWASP Foundation}},
title = {{OWASP Top 10 Privacy Risks}},
url = {https://owasp.org/www-project-top-10-privacy-risks/},
urldate = {2021-07-21}
}
@inproceedings{Reinheimer2020,
abstract = {Smart homes are under attack. Threats can harm both the security of these homes and the privacy of their inhabitants. As a result, in addition to delivering pleasing and aesthetic devices, smart home product designers need to factor security and privacy into the design of their devices. Further, the need for user-centered security and privacy design is particularly important for such an environment, given that inhabitants are demographically-diverse (e.g., age, gender, educational level) and have different skills and (dis)abilities. Prior work has explored different usable security and privacy solutions for smart homes; however, the applicability of user experience (UX) principles to security and privacy design is under-explored. In this paper, we present a qualitative study to explore the development of smart home cameras manufactured by three companies. We conduct semi-structured interviews with 20 designers and their collaborators, and analyze these interviews using Grounded Theory. We find that UX was seen as helpful by our participants in fostering innovation in the design of privacy solutions. However, UX was not used or considered in the design of security solutions due to an explicit need for established, tried-and-tested solutions (i.e., previous traditional security solutions that were seen as effective and reliable to fix certain design problems). Drawing from the findings of our study, we propose a model of UX factors influencing security and privacy design of smart home cameras. We also extract a set of recommendations to improve the security and privacy design of smart cameras. We finally outline several areas for future investigation.},
author = {Chalhoub, George and Flechais, Ivan and Nthala, Norbert and Abu-Salma, Ruba},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chalhoub et al. - 2020 - Innovation inaction or in action The role of user experience in the security and privacy design of smart home c.pdf:pdf},
pages = {185--204},
title = {{Innovation inaction or in action? The role of user experience in the security and privacy design of smart home cameras}},
year = {2020}
}
@article{ErolaArnau2011,
abstract = {Web search engines (WSE) have become an essential tool for searching information on the Internet. In order to provide personalized search results for the users, WSEs store all the queries which have been submitted by the users and the search results which they have selected. The AOL scandal in 2006 proved that this information contains personally identifiable information which represents a privacy threat for the users who have generated it. In this way, AOL released a file containing twenty million queries made by 658,000 persons and several of those users were successfully tracked. In this paper, we propose a P2P protocol that exploits social networks in order to protect the privacy of the users from the profiling mechanisms of the WSEs. The proposed scheme has been designed considering the presence of users who do not follow the protocol (i.e.; adversaries). In order to evaluate the privacy of the users, we have designed a new measure (the profile exposure level (PEL)). Finally, we have used the AOL's file in order to simulate the behavior of our scheme with real queries which have been generated by real users. Our tests show that our scheme is usable in practice and that it preserves the privacy of the users even in the presence of adversaries. {\textcopyright} 2011 Elsevier Inc.},
author = {Erola, Arnau and Castell-Roca, Jordi and Viejo, Alexandre and Mateo-Sanz, Josep M.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Erola et al. - 2011 - Exploiting social networks to provide privacy in personalized web search.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Privacy,Private information retrieval,Social networks,Web search},
number = {10},
pages = {1734--1745},
title = {{Exploiting social networks to provide privacy in personalized web search}},
volume = {84},
year = {2011}
}
@article{Bhandari2021,
abstract = {Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and Exposures (CVE) records in the public National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes. The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits. CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.},
author = {Bhandari, Guru Prasad and Naseer, Amara and Moonen, Leon},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhandari, Naseer, Moonen - 2021 - CVEfixes Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software.pdf:pdf},
keywords = {Security vulnerabilities,dataset,software repository mining,source code repair.,vulnerability classification,vulnerability prediction},
title = {{CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software}},
year = {2021}
}
@inproceedings{Mazhelis2007,
abstract = {Contemporary mobile terminals (smartphones, PDAs, communicators) are often used to store or access sensitive private or corporate information, and an unauthorized use of these terminals may result in an abuse of this information. In order to resist such unauthorized use, along with traditional authentication mechanisms, the means of masquerader detection can be employed. In this paper, the problem of mobile-masquerader detection is approached as a classification problem. The detection is based on the monitoring of the current user behavior and environment, and matching them with the behavior and the environment of the legitimate user. The matching is performed by an ensemble of the so-called one-class classifiers each analyzing a separate set of behavioral or environmental features, and classifying the current values of these features as belonging to the legitimate user or not. Using a combining scheme, the individual classifications of these classifiers are combined so as to improve the final classification accuracy. In the paper, three combining schemes are empirically compared in the context ofmobile-masquerader detection; these are the mean of the estimated probabilities (MP), the product combination of probabilities (PP), and the modified mean of the estimated probabilities (modMP) rules. According to the results of experiments, the use of modMP rule is justified in mobile-masquerader detection, since this rule provides the classification accuracy greater than or approximately equal to the accuracy of the other rules. Meanwhile, the obtained results suggest that, for the modMP rule to provide high classification accuracy, the means of the classifier outputs need to be estimated accurately. {\textcopyright}2007 IEEE.},
author = {Mazhelis, Oleksiy and Puuronen, Seppo},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazhelis, Puuronen - 2007 - Comparing classifier combining techniques for mobile-masquerader detection.pdf:pdf},
pages = {465--472},
title = {{Comparing classifier combining techniques for mobile-masquerader detection}},
year = {2007}
}
@inproceedings{Dev,
abstract = {The purpose of this study is to understand the privacy concerns and behavior of non-WEIRD populations in online messaging platforms. Analysis of surveys (n = 674) of WhatsApp users in Saudi Arabia and India revealed that Saudis had significantly higher concerns about being contacted by strangers. In contrast, Indians showed significantly higher concerns with respect to social contact from professional colleagues. Demographics impinge privacy preferences in both populations, but in different ways. Results from regression analysis show that there are statistically significant differences between the privacy behaviors of Saudis and Indians. In both cases, privacy concerns were strongly correlated with their reported privacy behaviors. Despite the differences, we identified technical solutions that could address the concerns of both populations of participants. We close by discussing the applicability of our recommendations, specifically those on transparency and consent, to other applications and domains.},
author = {Dev, Jayati and Moriano, Pablo and {Jean Camp}, L.},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dev, Moriano, Jean Camp - 2020 - Lessons learnt from comparing whatsapp privacy concerns across Saudi and Indian populations.pdf:pdf},
pages = {81--98},
title = {{Lessons learnt from comparing whatsapp privacy concerns across Saudi and Indian populations}},
year = {2020}
}
@techreport{Booth2016,
abstract = {This document aims to describe a more effective and efficient methodology for characterizing vulnerabilities found in various forms of software and hardware implementations including but not limited to information technology systems, industrial control systems or medical devices to assist in the vulnerability management process. The primary goal of the described methodology is to enable automated analysis using metrics such as the Common Vulnerability Scoring System (CVSS). Additional goals include establishing a baseline of the minimum information needed to properly inform the vulnerability management process, and facilitating the sharing of vulnerability information across language barriers.},
author = {Booth, Harold and Turner, Christopher},
booktitle = {NIST},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Booth, Turner - 2016 - Draft NISTIR 8138 Vulnerability Description Ontology.pdf:pdf},
keywords = {"software defects,ontology,patching,taxonomy,vulnerabilities,vulnerability management"},
title = {{Draft NISTIR 8138 Vulnerability Description Ontology}},
year = {2016}
}
@article{Lentzsch,
abstract = {Amazon's voice-based assistant, Alexa, enables users to directly interact with various web services through natural language dialogues. It provides developers with the option to create third-party applications (known as Skills) to run on top of Alexa. While such applications ease users' interaction with smart devices and bolster a number of additional services, they also raise security and privacy concerns due to the personal setting they operate in. This paper aims to perform a systematic analysis of the Alexa skill ecosystem. We perform the first large-scale analysis of Alexa skills, obtained from seven different skill stores totaling to 90,194 unique skills. Our analysis reveals several limitations that exist in the current skill vetting process. We show that not only can a malicious user publish a skill under any arbitrary developer/company name, but she can also make backend code changes after approval to coax users into revealing unwanted information. We, next, formalize the different skill-squatting techniques and evaluate the efficacy of such techniques. We find that while certain approaches are more favorable than others, there is no substantial abuse of skill squatting in the real world. Lastly, we study the prevalence of privacy policies across different categories of skill, and more importantly the policy content of skills that use the Alexa permission model to access sensitive user data. We find that around 23.3 {\%} of such skills do not fully disclose the data types associated with the permissions requested. We conclude by providing some suggestions for strengthening the overall ecosystem, and thereby enhance transparency for end-users.},
author = {Lentzsch, Christopher and Shah, Sheel Jayesh and Andow, Benjamin and Degeling, Martin and Das, Anupam and Enck, William},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lentzsch et al. - 2021 - Hey Alexa, is this Skill Safe Taking a Closer Look at the Alexa Skill Ecosystem.pdf:pdf},
journal = {Ndss'21},
number = {February},
title = {{Hey Alexa, is this Skill Safe?: Taking a Closer Look at the Alexa Skill Ecosystem}},
year = {2021}
}
@inproceedings{Yang2013,
abstract = {Android phones often carry personal information, attracting malicious developers to embed code in Android applications to steal sensitive data. With known techniques in the literature, one may easily determine if sensitive data is being transmitted out of an Android phone. However, transmission of sensitive data in itself does not necessarily indicate privacy leakage; a better indicator may be whether the transmission is by user intention or not. When transmission is not intended by the user, it is more likely a privacy leakage. The problem is how to determine if transmission is user intended. As a first solution in this space, we present a new analysis framework called AppIntent. For each data transmission, AppIntent can efficiently provide a sequence of GUI manipulations corresponding to the sequence of events that lead to the data transmission, thus helping an analyst to determine if the data transmission is user intended or not. The basic idea is to use symbolic execution to generate the aforementioned event sequence, but straightforward symbolic execution proves to be too time-consuming to be practical. A major innovation in AppIntent is to leverage the unique Android execution model to reduce the search space without sacrificing code coverage. We also present an evaluation of AppIntent with a set of 750 malicious apps, as well as 1,000 top free apps from Google Play. The results show that AppIntent can effectively help separate the apps that truly leak user privacy from those that do not. {\textcopyright} 2013 ACM.},
author = {Yang, Zhemin and Yang, Min and Zhang, Yuan and Gu, Guofei and Ning, Peng and Wang, X Sean},
booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2013 - AppIntent Analyzing sensitive data transmission in Android for privacy leakage detection.pdf:pdf},
keywords = {android security,privacy leakage detection,symbolic execution},
pages = {1043--1054},
title = {{AppIntent: Analyzing sensitive data transmission in Android for privacy leakage detection}},
year = {2013}
}
@inproceedings{Rafiq2017,
abstract = {Some online social networks (OSNs) allow users to define friendship-groups as reusable shortcuts for sharing information with multiple contacts. Posting exclusively to a friendship-group gives some privacy control, while supporting communication with (and within) this group. However, recipients of such posts may want to reuse content for their own social advantage, and can bypass existing controls by copy-pasting into a new post; this cross-posting poses privacy risks. This paper presents a learning to share approach that enables the incorporation of more nuanced privacy controls into OSNs. Specifically, we propose a reusable, adaptive software architecture that uses rigorous runtime analysis to help OSN users to make informed decisions about suitable audiences for their posts. This is achieved by supporting dynamic formation of recipient-groups that benefit social interactions while reducing privacy risks. We exemplify the use of our approach in the context of Facebook.},
author = {Rafiq, Yasmin and Dickens, Luke and Russo, Alessandra and Bandara, Arosha K. and Yang, Mu and Stuart, Avelie and Levine, Mark and Calikli, Gul and Price, Blaine A. and Nuseibeh, Bashar},
booktitle = {ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
month = {nov},
pages = {280--285},
title = {{Learning to share: Engineering adaptive decision-support for online social networks}},
year = {2017}
}
@article{Kalloniatis2008,
abstract = {A major challenge in the field of software engineering is to make users trust the software that they use in their every day activities for professional or recreational reasons. Trusting software depends on various elements, one of which is the protection of user privacy. Protecting privacy is about complying with user's desires when it comes to handling personal information. Users' privacy can also be defined as the right to determine when, how and to what extend information about them is communicated to others. Current research stresses the need for addressing privacy issues during the system design rather than during the system implementation phase. To this end, this paper describes PriS, a security requirements engineering method, which incorporates privacy requirements early in the system development process. PriS considers privacy requirements as organisational goals that need to be satisfied and adopts the use of privacy-process patterns as a way to: (1) describe the effect of privacy requirements on business processes; and (2) facilitate the identification of the system architecture that best supports the privacy-related business processes. In this way, PriS provides a holistic approach from 'high-level; goals to 'privacy-compliant' IT systems. The PriS way-of-working is formally defined thus, enabling the development of automated tools for assisting its application. {\textcopyright} Springer-Verlag London Limited 2008.},
author = {Kalloniatis, Christos and Kavakli, Evangelia and Gritzalis, Stefanos},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalloniatis, Kavakli, Gritzalis - 2008 - Addressing privacy requirements in system design The PriS method.pdf:pdf},
journal = {Requirements Engineering},
keywords = {Formal methods,Goal-oriented approach,Privacy enhancing technologies,Privacy requirements,Privacy-process patterns,Requirements engineering,System design},
number = {3},
pages = {241--255},
title = {{Addressing privacy requirements in system design: The PriS method}},
volume = {13},
year = {2008}
}
@misc{Statista2021,
abstract = {The biggest data breach as of April 2020 was thr summer 2018 security breach of sales intelligence company Apollo. During the security breach, over 9 billion data points related to companies and organizations were revealed. In August 2016, a 2014 hack of online platform Yahoo was uncovered, affecting at least 500 million users accounts. In December 2016, the company revealed another hack dating back to 2013, which affected 1 billion user records. The impact of the second reported Yahoo hack was updated in October 2017, when the company revealed that 3 billion accounts had been affected, making it the largest data breach in the company's history.},
author = {Johnson, Joseph},
booktitle = {Statista},
title = {{Cyber crime: biggest online data breaches as of 2020}},
url = {https://www.statista.com/statistics/290525/cyber-crime-biggest-online-data-breaches-worldwide/},
year = {2021}
}
@misc{DataPrivacyManager2021,
author = {{Data Privacy Manager}},
title = {{5 things you need to know about Data Privacy}},
url = {https://dataprivacymanager.net/5-things-you-need-to-know-about-data-privacy/},
urldate = {2021-08-25},
year = {2021}
}
@inproceedings{Volkamer2006,
abstract = {Internet-based elections have become more and more popular in the last five years. In future a lot of people are probably going to cast their ballot over the Internet. This could be a great benefit. But at the same time new possibilities to manipulate the election will arise: Besides other network specific attacks, sniffing of the network traffic becomes interesting. This paper identifies the problems with respect to temporal unlimited election secrecy against sniffing on the network. The problem is the voter's IP address and the fact that in practice, there is no anonymous communication channel. Thus the voter's anonymity can be broken in future. However, the attacker will not be able to proof his knowledge about the voter's decision. We will figure out how this vulnerability could be prevented with state of the art technologies. {\textcopyright} 2006 IEEE.},
author = {Volkamer, Melanie and Krimmer, Robert},
booktitle = {Proceedings - First International Conference on Availability, Reliability and Security, ARES 2006},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Volkamer, Krimmer - 2006 - Secrecy forever Analysis of anonymity in internet-based voting protocols.pdf:pdf},
pages = {340--347},
title = {{Secrecy forever? Analysis of anonymity in internet-based voting protocols}},
volume = {2006},
year = {2006}
}
@inproceedings{Zeng2019,
abstract = {The Internet of Things is becoming increasingly widespread in home environments. Consumers are transforming their homes into smart homes, with internet-connected sensors, lights, appliances, and locks, controlled by voice or other user-defined automations. Security experts have identified concerns with IoT and smart homes, including privacy risks as well as vulnerable and unreliable devices. These concerns are supported by recent high profile attacks, such as the Mirai DDoS attacks. However, little work has studied the security and privacy concerns of end users who actually set up and interact with today's smart homes. To bridge this gap, we conduct semi-structured interviews with fifteen people living in smart homes (twelve smart home administrators and three other residents) to learn about how they use their smart homes, and to understand their security and privacy related attitudes, expectations, and actions. Among other findings, we identify gaps in threat models arising from limited technical understanding of smart homes, awareness of some security issues but limited concern, ad hoc mitigation strategies, and a mismatch between the concerns and power of the smart home administrator and other people in the home. From these and other findings, we distill recommendations for smart home technology designers and future research.},
author = {Zeng, Eric and Mare, Shrirang and Roesner, Franziska},
booktitle = {Proceedings of the 13th Symposium on Usable Privacy and Security, SOUPS 2017},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeng, Mare, Roesner - 2019 - End user security and privacy concerns with smart homes.pdf:pdf},
pages = {65--80},
title = {{End user security and privacy concerns with smart homes}},
url = {https://www.usenix.org/conference/soups2017/technical-sessions/presentation/acar},
year = {2019}
}
@inproceedings{Groba2007,
abstract = {Following Mark Weiser's vision of ubiquitous computing and calm technology, computer systems should run in the background, preferably without the user noticing it at all. The gathering and disclosure of contextual information on the one hand enables the improvement of system behaviour towards a more autonomous and adaptive behaviour but on the other hand raises privacy issues by disclosing personal data. Thus, a major challenge in ubiquitous computing environments is achieving a good balance between convenience and control over personal data. In this paper we describe an access control mechanism for context data that enables the user to control his personal data in a convenient and non-intrusive way. The approach is based on existing role-based access control mechanisms but extends them as follows. Firstly, our approach is owner-centric, i.e. it is under control of each user, to whom his context is propagated throughout the system. Secondly, our approach does not only control the access to context data but also utilizes context information to simplify the management of these control mechanisms to make the handling of access control more convenient to the user. And thirdly, it introduces individual roles for each user and thus replaces the centrally defined role model of common rolebased access control by distinct models for each user. We have validated our approach based on an extended instant messaging system called Adaptive Multimedia Messenger, providing varying buddy information dependent on the access permission of the requesting user. {\textcopyright} 2007 IEEE.},
author = {Groba, Christin and Gro{\ss}, Stephan and Springer, Thomas},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Groba, Gro{\ss}, Springer - 2007 - Context-dependent access control for contextual information.pdf:pdf},
pages = {155--161},
title = {{Context-dependent access control for contextual information}},
year = {2007}
}
@incollection{Kalloniatis2018,
abstract = {Pervasiveness of information systems is well underway, redefining our social and economic relationships. This technological revolution has generated enormous capabilities, but also enabled the creation of new vulnerabilities and threats. A major challenge in the field of information systems is therefore, to ensure the trustworthiness of the underlying technologies that make possible the generation, collection, storage, processing and transmission of user data at rates more intensive than ever before. Trust in information systems depends on different aspects, one of which is the security of user's data. Data security is referred as the protection of user's data from corruption and unauthorized access. Another important aspect of trust is the protection of user's privacy. Protecting privacy is about complying with user's desires when it comes to handling personal information. Without security to guarantee data protection, appropriate uses of that data cannot be realized. This implies that security and privacy issues are inherently intertwined and should be viewed synergistically. The aim of this paper is to elevate modern practices for ensuring security and privacy during software systems analysis and design. To this end, the basic security and privacy requirements that should be considered are introduced. Additionally, a number of well known methods in the research area of requirements engineering which focus on eliciting and modeling security and privacy requirements are described. Finally, a comparative analysis between these methods is presented.},
author = {Kalloniatis, Christos and Pattakou, Argyri and Kavakli, Evangelia and Gritzalis, Stefanos},
booktitle = {Censorship, Surveillance, and Privacy: Concepts, Methodologies, Tools, and Applications},
pages = {390--418},
title = {{Designing secure and privacy-aware information systems}},
volume = {1},
year = {2018}
}
@inproceedings{Bhatia2016a,
abstract = {Ambiguity arises in requirements when astatement is unintentionally or otherwise incomplete, missing information, or when a word or phrase has morethan one possible meaning. For web-based and mobileinformation systems, ambiguity, and vagueness inparticular, undermines the ability of organizations to aligntheir privacy policies with their data practices, which canconfuse or mislead users thus leading to an increase inprivacy risk. In this paper, we introduce a theory ofvagueness for privacy policy statements based on ataxonomy of vague terms derived from an empiricalcontent analysis of 15 privacy policies. The taxonomy wasevaluated in a paired comparison experiment and resultswere analyzed using the Bradley-Terry model to yield arank order of vague terms in both isolation andcomposition. The theory predicts how vague modifiers toinformation actions and information types can becomposed to increase or decrease overall vagueness. Wefurther provide empirical evidence based on factorialvignette surveys to show how increases in vagueness willdecrease users' acceptance of privacy risk and thusdecrease users' willingness to share personal information.},
author = {Bhatia, Jaspreet and Breaux, Travis D. and Reidenberg, Joel R. and Norton, Thomas B.},
booktitle = {Proceedings - 2016 IEEE 24th International Requirements Engineering Conference, RE 2016},
keywords = {hedging,natural language processing,privacy,risk perception,vagueness},
pages = {26--35},
title = {{A Theory of Vagueness and Privacy Risk Perception}},
year = {2016}
}
@inproceedings{Jorns2007,
abstract = {Network operators gradually open their interfaces to formerly hidden services. This fosters the development of a new class of mobile applications that take into account user's location and presence information. However, this development also raises problems especially the lack of protection of privacy in location-based services. This paper proposes a service architecture that is aimed at overcoming some of the shortages of currently existing context-aware applications that make use of network providers services as well as existing mobile payment systems. We therefore introduce the combination of tickets together with a novel privacy enhancing mechanism that is based on the notion of pseudonyms. Compared to other privacy enhancing solutions our pseudonym mechanism can also be implemented on mobile devices that have some restrictions regarding resources like memory or processing power. Due to their flexibility tickets can be used for many different kinds of applications. One important aspect in this respect is the highly postulated pay-as-you-go model. We give an example of a transport ticket application and explain the message interaction patterns for the basic functionalities of the systems, regarding aspects like data and privacy protection. This example further shows how 3rd party application providers can build meaningful mobile applications that are accepted by users. {\textcopyright} 2007 IEEE.},
author = {J{\"{o}}rns, Oliver and Jung, Oliver and Quirchmayr, Gerald},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
doi = {10.1109/ARES.2007.16},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/J{\"{o}}rns, Jung, Quirchmayr - 2007 - A privacy enhancing service architecture for ticket-based mobile applications.pdf:pdf},
isbn = {0769527752},
pages = {139--146},
title = {{A privacy enhancing service architecture for ticket-based mobile applications}},
year = {2007}
}
@article{Wuyts2014,
abstract = {Privacy is a key issue in today's society. Software systems handle more and more sensitive information concerning citizens. It is important that such systems are privacy-friendly by design. In previous work, we proposed a privacy threat analysis methodology, named LINDDUN. The methodology supports requirements engineers and software architects in identifying privacy weaknesses in the system they contribute to developing. As this is a fairly new technique, its results when applied in realistic scenarios are yet unknown. This paper presents a series of three empirical studies that thoroughly evaluate LINDDUN from a multi-faceted perspective. Our assessment characterizes the correctness and completeness of the analysis results produced by LINDDUN, as well as the productivity associated with executing the methodology. We also look into aspects such as the ease of use and reliability of LINDDUN. The results are encouraging, overall. However, some areas for further improvement have been identified as a result of this empirical inquiry. {\textcopyright} 2014 Elsevier Inc.},
author = {Wuyts, Kim and Scandariato, Riccardo and Joosen, Wouter},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wuyts, Scandariato, Joosen - 2014 - Empirical evaluation of a privacy-focused threat modeling methodology.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Empirical study,Privacy,Threats},
pages = {122--138},
title = {{Empirical evaluation of a privacy-focused threat modeling methodology}},
volume = {96},
year = {2014}
}
@inproceedings{Mache2007,
abstract = {The purpose of RFID tags is to provide identifying information; the problem is that tags may radiate identifying information to any RFID reader anywhere. Encryption alone does not help: even encrypted IDs are static, and can be identified as unique to a particular object, and are thus vulnerable to tracking. To preserve privacy, pseudonym protocols have been proposed. Using cryptography and pseudonyms, unauthorized entities cannot even link two sightings of the same tag. In this paper, we measure the cost of running tree-based pseudonym protocols. Pseudonym protocols require random numbers, cryptographic operations and writing to onboard memory (in case time-limited delegation is enabled), which we implement using TinyOS system software. For MicaZ hardware, we measure voltage drop with an oscilloscope. Our results show that one SkipJack block cipher (part of the pseudonym encryption process) costs more energy than generating ten random numbers. Therefore, when configuring the tree of secrets, it is more energy-efficient to have a wider rather than a deeper tree. {\textcopyright} 2007 IEEE.},
author = {Mache, Jens and Allick, Chris},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mache, Allick - 2007 - The cost of preserving privacy Performance measurements of RFID pseudonym protocols.pdf:pdf},
keywords = {Performance evaluation,Privacy,Pseudonym protocol,RFID,Security},
pages = {606--609},
title = {{The cost of preserving privacy: Performance measurements of RFID pseudonym protocols}},
year = {2007}
}
@misc{OWASP2020,
author = {{Open Web Application Security Project}},
title = {{About Us | The OWASP Foundation}},
url = {https://owasp.org/about/},
urldate = {2021-08-22},
year = {2020}
}
@inproceedings{Fisk2015,
abstract = {Sharing cyber security data across organizational boundaries brings both privacy risks in the exposure of personal information and data, and organizational risk in disclosing internal information. These risks occur as information leaks in network traffic or logs, and also in queries made across organizations. They are also complicated by the trade-offs in privacy preservation and utility present in anonymization to manage disclosure. In this paper, we define three principles that guide sharing security information across organizations: Least Disclosure, Qualitative Evaluation, and Forward Progress. We then discuss engineering approaches that apply these principles to a distributed security system. Application of these principles can reduce the risk of data exposure and help manage trust requirements for data sharing, helping to meet our goal of balancing privacy, organizational risk, and the ability to better respond to security with shared information.},
author = {Fisk, Gina and Ardi, Calvin and Pickett, Neale and Heidemann, John and Fisk, Mike and Papadopoulos, Christos},
booktitle = {Proceedings - 2015 IEEE Security and Privacy Workshops, SPW 2015},
keywords = {Cyber security,Data confinement,Data sharing,Forward progress,Least disclosure,Minimal requisite fidelity,Moderated queries,Poker queries,Privacy principles,Qualitative evaluation},
pages = {193--197},
title = {{Privacy principles for sharing cyber security data}},
year = {2015}
}
@misc{HIPAA,
author = {{Department of Health and Human Services}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Department of Health and Human Services - 2013 - HIPAA administrative simplification regulation text.pdf:pdf},
pages = {1--115},
title = {{HIPAA administrative simplification regulation text}},
url = {https://www.hhs.gov/sites/default/files/hipaa-simplification-201303.pdf},
year = {2013}
}
@inproceedings{Iyilade2014,
abstract = {Within the last decade, there are growing economic social incentives and opportunities for secondary use of data in many sectors, and strong market forces currently drive the active development of systems that aggregate user data gathered by many sources. This secondary use of data poses privacy threats due to unwanted use of data for the wrong purposes such as discriminating the user for employment, loan and insurance. Traditional privacy policy languages such as the Platform for Privacy Preferences (P3P) are inadequate since they were designed long before many of these technologies were invented and basically focus on enabling user-awareness and control during primary data collection (e.g. by a website). However, with the advent of Web 2.0 and Social Networking Sites, the landscape of privacy is shifting from limiting collection of data by websites to ensuring ethical use of the data after initial collection. To meet the current challenges of privacy protection in secondary context, we propose a privacy policy language, Purpose-to-Use (P2U), aimed at enforcing privacy while enabling secondary user information sharing across applications, devices, and services on the Web.},
author = {Iyilade, Johnson and Vassileva, Julita},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Policy Languages,Privacy,Secondary Use,Usage Control},
pages = {18--22},
title = {{P2U: A privacy policy specification language for secondary data sharing and usage}},
volume = {2014-Janua},
year = {2014}
}
@inproceedings{Lee2006,
abstract = {Radio Frequency Identification (RFID) technology that is used to identify objects and users and automatically takes advantage of contextual information such as user's location is expected to become an important and a core technology of ubiquitous infrastructure. This technology has been applied to many applications such as retail and supply chain. At recent, there are an increasing number of researches related to mobile RFID that provides RFID service to user with a reader embedded in the mobile device as the one of RFID applications. However, there are an increasing number of concerns, and even some resistance, related to user tracking and profiling using RFID technology. Therefore, in this paper, we review privacy threats that have been reported in various RFID applications and bring up some additional privacy threats in mobile RFID, impeding the deployment of mobile RFID. And we analyze whether various privacy protecticng measures that have been proposed to address privacy problems in RFID can also apply to mobile RFID. {\textcopyright} 2006 IEEE.},
author = {Lee, Hyangjin and Kim, Jeeyeon},
booktitle = {Proceedings - First International Conference on Availability, Reliability and Security, ARES 2006},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Kim - 2006 - Privacy threats and issues in mobile RFID.pdf:pdf},
pages = {510--514},
title = {{Privacy threats and issues in mobile RFID}},
volume = {2006},
year = {2006}
}
@article{Chakraborty2021,
abstract = {Automated detection of software vulnerabilities is a fundamental problem in software security. Existing program analysis techniques either suffer from high false positives or false negatives. Recent progress in Deep Learning (DL) has resulted in a surge of interest in applying DL for automated vulnerability detection. Several recent studies have demonstrated promising results achieving an accuracy of up to 95{\%} at detecting vulnerabilities. In this paper, we ask, "how well do the state-of-the-art DL-based techniques perform in a real-world vulnerability prediction scenario?". To our surprise, we find that their performance drops by more than 50{\%}. A systematic investigation of what causes such precipitous performance drop reveals that existing DL-based vulnerability prediction approaches suffer from challenges with the training data (e.g., data duplication, unrealistic distribution of vulnerable classes, etc.) and with the model choices (e.g., simple token-based models). As a result, these approaches often do not learn features related to the actual cause of the vulnerabilities. Instead, they learn unrelated artifacts from the dataset (e.g., specific variable/function names, etc.). Leveraging these empirical findings, we demonstrate how a more principled approach to data collection and model design, based on realistic settings of vulnerability prediction, can lead to better solutions. The resulting tools perform significantly better than the studied baseline: up to 33.57{\%} boost in precision and 128.38{\%} boost in recall compared to the best performing model in the literature. Overall, this paper elucidates existing DL-based vulnerability prediction systems' potential issues and draws a roadmap for future DL-based vulnerability prediction research. In that spirit, we make available all the artifacts supporting our results: https://git.io/Jf6IA.},
author = {Chakraborty, Saikat and Krishna, Rahul and Ding, Yangruibo and Ray, Baishakhi},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakraborty et al. - 2021 - Deep Learning based Vulnerability Detection Are We There Yet.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {Deep Learning,Graph Neural Network !,Index Terms-Software Vulnerability},
title = {{Deep Learning based Vulnerability Detection: Are We There Yet?}},
volume = {TBD},
year = {2021}
}
@misc{Purplesec2021,
author = {Purplesec},
title = {{2021 Cyber Security Statistics The Ultimate List Of Stats, Data {\&} Trends PurpleSec}},
url = {https://purplesec.us/resources/cyber-security-statistics/},
urldate = {2021-08-03},
year = {2021}
}
@inproceedings{Seeberg2007,
abstract = {Artificially generated network traffic sources for IDS benchmarking have been harshly criticized because of their inability to realistically simulate networks. Benchmarking data sets based on real data have many advantages over the artificially generated ones, but due to privacy concerns and legal restrictions such original data sets cannot be widely distributed. Their anonymization ("sanitization") is necessary in order to be used in IDS testing. In this paper, we define a new variable strength filter-in methodology of anonymization of IDS benchmarking data sets. It is based on an original classification criterion used to categorize informational objects in network data according to the action to be performed on them in the anonymization process. The action depends on the possibility of these objects to disclose sensitive information. We analyze the possibility of disclosing sensitive information by various http header fields. We also study influence of application of the new anonymization methodology on percentage of attacks detectable by an IDS. Experimental results show that a great number of the attacks present in the input data without anonymization are still detectable by the tested IDS even after the application of the strongest anonymization scheme defined by our methodology. Although the new anonymization method focuses on application data, it could also be used in the link, network, and transport protocol contexts. {\textcopyright} 2007 IEEE.},
author = {Seeberg, Vidar Evenrud and Petrovi{\'{c}}, Slobodan},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Seeberg, Petrovi{\'{c}} - 2007 - A new classification scheme for anonymization of real data used in IDS benchmarking.pdf:pdf},
pages = {385--390},
title = {{A new classification scheme for anonymization of real data used in IDS benchmarking}},
year = {2007}
}
@techreport{ISO/IEC2011,
author = {ISO/IEC},
institution = {ISO/IEC},
title = {{International Standard ISO/IEC 29100}},
year = {2011}
}
@article{Tschersich,
abstract = {With the advent of mobile broadband technologies and capable mobile devices, social communities become a ubiquitous environment for people to stay in contact and share information with friends and fellows. This provides new opportunities for communities and their providers (e.g. regarding advertising) but also implies new question regarding the privacy and trust of their users. We argue that a balance needs to be found between these (partially) diverging interests and motivate, why a new approach to identity management and users privacy is necessary in this context. Based on requirements retrieved by real-life communities, we describe an architecture including privacy enhancing concepts and advanced privacy respecting advertising, which addresses such requirements. We further describe the architectures' prototypical implementation, and present for the first time evaluation results based on user trials with two different mobile communities. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
author = {Tschersich, Markus and Kahl, Christian and Heim, Stephan and Crane, Stephen and B{\"{o}}ttcher, Katja and Krontiris, Ioannis and Rannenberg, Kai},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tschersich et al. - 2011 - Towards privacy-enhanced mobile communities - Architecture, concepts and user trials.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Identity management,Mobile communities,Privacy,Targeted advertising,Trust},
number = {11},
pages = {1947--1960},
title = {{Towards privacy-enhanced mobile communities - Architecture, concepts and user trials}},
volume = {84},
year = {2011}
}
@misc{Statista2021b,
author = {Johnson, Joseph},
booktitle = {Statista},
title = {{Internet users in the world 2021}},
url = {https://www.statista.com/statistics/617136/digital-population-worldwide/},
urldate = {2021-08-03},
year = {2021}
}
@article{Gurses2016,
abstract = {Addressing privacy and data protection systematically throughout the process of engineering information systems is a daunting task. Although the research community has made significant progress in theory and in labs, meltdowns in recent years suggest that we're still struggling to address systemic privacy issues. Privacy engineering, an emerging field, responds to this gap between research and practice. It's concerned with systematizing and evaluating approaches to capture and address privacy issues with engineering information systems. This article serves to illuminate this nascent field. The authors provide a definition of privacy engineering and describe encompassing activities. They expand on these with findings from the First International Workshop on Privacy Engineering (IWPE), and conclude with future challenges.},
author = {G{\"{u}}rses, Seda and {Del {\'{A}}lamo}, Jos{\'{e}} M.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}rses, Del {\'{A}}lamo - 2016 - Privacy Engineering Shaping an Emerging Field of Research and Practice.pdf:pdf},
journal = {IEEE Security and Privacy},
keywords = {Computer security,Data privacy,Law,Positron emission tomography,Privacy},
number = {2},
pages = {40--46},
title = {{Privacy Engineering: Shaping an Emerging Field of Research and Practice}},
volume = {14},
year = {2016}
}
@inproceedings{Kotz2011,
abstract = {Networked mobile devices have great potential to enable individuals (and their physicians) to better monitor their health and to manage medical conditions. In this paper, we examine the privacy-related threats to these so-called mHealth technologies. We develop a taxonomy of the privacy-related threats, and discuss some of the technologies that could support privacy-sensitive mHealth systems. We conclude with a brief summary of research challenges. {\textcopyright} 2011 IEEE.},
author = {Kotz, David},
booktitle = {2011 3rd International Conference on Communication Systems and Networks, COMSNETS 2011},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kotz - 2011 - A threat taxonomy for mHealth privacy.pdf:pdf},
title = {{A threat taxonomy for mHealth privacy}},
year = {2011}
}
@inproceedings{Kalloniatis2007,
abstract = {In the online world every person has to hold a number of different data sets so as to be able to have access to various e-services and take part in specific economical and social transactions. Such data sets require special consideration since they may convey personal data, sensitive personal data, employee data, credit card data etc. Recent surveys have shown that people feel that their privacy is at risk from identity theft and erosion of individual rights. The result is that privacy violation is becoming an increasingly critical issue in modern societies. To this end, PriS, a new security requirements engineering methodology, has been introduced aiming to incorporate privacy requirements early in the system development process. In this paper, we extend the PriS conceptual framework by introducing privacy process patterns as a way for describing the effect of privacy requirements on business processes. In addition, privacy process patterns facilitate the identification of the system architecture that best supports the privacy-related business processes, thus providing a holistic approach from business goals to 'privacy-compliant' IT systems. {\textcopyright} 2007 IEEE.},
author = {Kalloniatis, Christos and Kavakli, Evangelia and Gritzalis, Stefanos},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalloniatis, Kavakli, Gritzalis - 2007 - Using privacy process patterns for incorporating privacy requirements into the system design pr.pdf:pdf},
pages = {1009--1016},
title = {{Using privacy process patterns for incorporating privacy requirements into the system design process}},
year = {2007}
}
@inproceedings{Nguyen2007,
abstract = {With rapid developments of network technologies, database outsourcing is emerging as an important new trend beside the "application-as-a- service". In this model, data owners ship their data to external service providers. Service providers do data management tasks and offer their clients a mechanism to manipulate outsourced databases. Since a service provider is not always fully trusted, security and privacy of outsourced data are significant issues. These problems are referred to as data confidentiality, user privacy, data privacy and query assurance. Among them, query assurance takes a crucial role to the success of the database outsourcing model. To the best of our knowledge, however, query assurance, especially for outsourced XML databases, has not been concerned reasonably in any previous work. In this paper, we propose a novel index structure, Nested Merkle B+-Tree, combining the advantages of B--tree and Merkle Hash Tree to completely deal with three issues of query assurance known as correctness, completeness and freshness in dynamic outsourced XML databases. Experimental results with real datasets prove the effeciency of our proposed solution. {\textcopyright} 2007 IEEE.},
author = {Nguyen, Viet Hung and Dang, Tran Khanh and Son, Nguyen Thanh and K{\"{u}}ng, Josef},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2007 - Query assurance verification for dynamic outsourced XML databases.pdf:pdf},
isbn = {0769527752},
pages = {689--696},
title = {{Query assurance verification for dynamic outsourced XML databases}},
year = {2007}
}
@inproceedings{Gonzalez2019,
abstract = {Preventing vulnerability exploits is a critical software maintenance task, and software engineers often rely on Common Vulnerability and Exposure (CVEs) reports for information about vulnerable systems and libraries. These reports include descriptions, disclosure sources, and manually-populated vulnerability characteristics such as root cause from the NIST Vulnerability Description Ontology (VDO). This information needs to be complete and accurate so stakeholders of affected products can prevent and react to exploits of the reported vulnerabilities. In this study, we demonstrate that VDO characteristics can be automatically detected from the textual descriptions included in CVE reports. We evaluated the performance of 6 classification algorithms with a dataset of 365 vulnerability descriptions, each mapped to 1 of 19 characteristics from the VDO. This work demonstrates that it is feasible to train classification techniques to accurately characterize vulnerabilities from their descriptions. All 6 classifiers evaluated produced accurate results, and the Support Vector Machine classifier was the best-performing individual classifier. Automating the vulnerability characterization process is a step towards ensuring stakeholders have the necessary data to effectively maintain their systems.},
author = {Gonzalez, Danielle and Hastings, Holly and Mirakhorli, Mehdi},
booktitle = {Proceedings - 2019 IEEE International Conference on Software Maintenance and Evolution, ICSME 2019},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez, Hastings, Mirakhorli - 2019 - Automated Characterization of Software Vulnerabilities.pdf:pdf},
keywords = {CVE,VDO,software maintainence,text classification,vulnerability characterization},
pages = {135--139},
title = {{Automated Characterization of Software Vulnerabilities}},
year = {2019}
}
@misc{Norton,
author = {Norton},
title = {{Why Your Online Privacy Matters}},
url = {https://us.norton.com/internetsecurity-privacy-why-your-online-privacy-matters.html},
urldate = {2021-08-20},
year = {2021}
}
@techreport{OAIC2021,
abstract = {The Office of the Australian Information Commissioner (OAIC) periodically publishes statistical information about notifications received under the Notifiable Data Breaches (NDB) scheme to assist entities and the public to understand the operation of the scheme. This report captures notifications made under the NDB scheme for the period from 1 July to 31 December 2020. Where data breaches affect multiple entities, the OAIC may receive multiple notifications relating to the same breach. Notifications relating to the same incident are counted as a single notification in this report. The source of any given breach is based on information provided by the reporting entity. Where more than one source has been identified or is possible, the dominant or most likely source has been selected. Source of breach categories are defined in the glossary at the end of this report. As with previous reports, notifications made under the My Health Records Act 2012 are not included as they are subject to specific notification requirements set out in that Act. NDB scheme statistics in this report are current as of 8 January 2021. However, a number of notifications included in these statistics are still under assessment and their status and categorisation are subject to change. This may affect statistics for the period July to December 2020 that are published in future reports. Similarly, there may have been adjustments to statistics in previous NDB reports because of changes to the status or categorisation of individual notifications after publication. As a result, references to statistics from before July 2020 in this report may differ from references in earlier published reports.},
author = {{The Office of the Australian Information Commissioner (OAIC)}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Office of the Australian Information Commissioner (OAIC) - 2021 - Notifiable Data Breaches Report.pdf:pdf},
number = {December 2020},
title = {{Notifiable Data Breaches Report}},
year = {2021}
}
@article{Zhang2005a,
abstract = {This paper presents a novel protocol for the revocation of privacy-enhanced/anonymous public-key certificates in relation to a protocol for anonymous public-key certificate issuing published previously. Not only can this certificate revocation protocol revoke an anonymous public-key certificate upon a request from its holder, but also automatically revoke any certificate issued directly or indirectly based on the certificate revoked, in an anonymous and accountable manner. In case the private key associated with an anonymous public-key certificate is suspected of having been compromised, the certificate holder can operate the protocol to easily revoke the compromised certificate together with its related ones so as to stop them being abused. The protocol is also assessed with regard to requirements such as accountability and anonymity. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Zhang, N. and Shi, Q. and Merabti, M.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Shi, Merabti - 2005 - Revocation of privacy-enhanced public-key certificates.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Anonymity,Communication protocol,E-commerce,Privacy,Public-key certificate},
number = {1-2},
pages = {205--214},
title = {{Revocation of privacy-enhanced public-key certificates}},
volume = {75},
year = {2005}
}
@misc{CWE,
author = {{The MITRE Corporation}},
pages = {The MITRE Corporation.},
title = {{About CWE}},
url = {https://cwe.mitre.org/about/index.html},
urldate = {2021-07-20},
year = {2021}
}
@inproceedings{Cetinkaya2007,
abstract = {Voter anonymity, also known as unlinkability, is the primary requirement to satisfy privacy in e-voting protocols. Up until now, e-voting protocols have tried to make communication channels anonymous in order to keep voter's identity hidden and many protocols have been proposed to construct anonymous communication channels. On the other hand, instead of making channel anonymous if we provide anonymous credentials to voter, we can easily hide voter's identity without any need of anonymous channels. This paper introduces Pseudo-Voter Identity (PVID) scheme based on blind signature in order to achieve anonymity in e-voting protocols. Blind signature is applied on pseudo identities selected by voter. Therefore voter obtains blindly signed pseudo identities namely PVIDs and uses them throughout the entire communication with the authorities. By using PVID scheme, e-voting protocols do not need anonymous channels anymore. This work aims at bringing unlinkable pseudo-voter identities based on blind signature bear on anonymous e-voting protocols. {\textcopyright} 2007 IEEE.},
author = {Cetinkaya, Orhan and Doganaksoy, Ali},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cetinkaya, Doganaksoy - 2007 - Pseudo-Voter Identity (PVID) scheme for e-voting protocols.pdf:pdf},
pages = {1190--1196},
title = {{Pseudo-Voter Identity (PVID) scheme for e-voting protocols}},
year = {2007}
}
@inproceedings{Reinheimer2020c,
abstract = {Most people are unfamiliar with the kinds of inferences that platforms like Facebook and Google can automatically associate with them, despite the existence of interfaces designed to provide transparency to end users. We conducted a study to investigate people's reactions upon being exposed to these inferences, to learn if and how they perceived the inferences to be connected to themselves. Through qualitative analysis, we found that the evidence participants used to relate the inferences with their self-perceptions was bounded by what they remembered about their own past behaviors in connection with the platform. Inferences that participants felt were implausible given their own behavior were rationalized as being related to family members, outdated, or could fit anyone with similar demographic characteristics. Participants also identified some inferences they believed had no connection with themselves whatsoever. We discuss implications for how participants' reasoning might lead to expectations about what kinds of inferences are possible, and what this means for people's ability to make informed privacy decisions regarding consent and disclosure.},
author = {Rader, Emilee and Hautea, Samantha and Munasinghe, Anjali},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rader, Hautea, Munasinghe - 2020 - “I have a narrow thought process” Constraints on explanations connecting inferences and self-percepti.pdf:pdf},
pages = {457--488},
title = {{“I have a narrow thought process”: Constraints on explanations connecting inferences and self-perceptions}},
year = {2020}
}
@article{Mouratidis2013,
abstract = {Cloud computing is an evolving paradigm that is radically changing the way humans store, share and access their digital files. Despite the many benefits, such as the introduction of a rapid elastic resource pool, and on-demand service, the paradigm also creates challenges for both users and providers. In particular, there are issues related to security and privacy, such as unauthorised access, loss of privacy, data replication and regulatory violation that require adequate attention. Nevertheless, and despite the recent research interest in developing software engineering techniques to support systems based on the cloud, the literature fails to provide a systematic and structured approach that enables software engineers to identify security and privacy requirements and select a suitable cloud service provider based on such requirements. This paper presents a novel framework that fills this gap. Our framework incorporates a modelling language and it provides a structured process that supports elicitation of security and privacy requirements and the selection of a cloud provider based on the satisfiability of the service provider to the relevant security and privacy requirements. To illustrate our work, we present results from a real case study. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Mouratidis, Haralambos and Islam, Shareeful and Kalloniatis, Christos and Gritzalis, Stefanos},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mouratidis et al. - 2013 - A framework to support selection of cloud providers based on security and privacy requirements.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Cloud computing,Privacy,Secure,software engineering},
number = {9},
pages = {2276--2293},
title = {{A framework to support selection of cloud providers based on security and privacy requirements}},
volume = {86},
year = {2013}
}
@inproceedings{Alsamani2018,
abstract = {Potential Security and Privacy concerns are widely discussed in the community of Internet of Things (IoT); however, the issue is still not fully addressed, and the demands for new methods of investigation are highly appraised. The current published research focused more on identifying the security issues associated with early type of IoT's applications based on sensors, such as RFID and WSN. However, todays IoT commercial applications are more advanced and use different of integrated objects. This research paper utilizes Design Science Research (DSR) methodology to better understand the security and privacy issue in IoT through creating an artifact. The purpose of this study is to propose taxonomy in order to categorize IoT's objects, so security and privacy issues would be fully addressed.},
author = {Alsamani, Badr and Lahza, Husam},
booktitle = {2018 International Conference on Information and Computer Technologies, ICICT 2018},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alsamani, Lahza - 2018 - A taxonomy of IoT Security and privacy threats.pdf:pdf},
keywords = {IoT,IoT objects,internet of things,privacy,security},
pages = {72--77},
title = {{A taxonomy of IoT: Security and privacy threats}},
year = {2018}
}
@article{Solove,
abstract = {Privacy is a concept in disarray. Nobody can articulate what it means. As one commentator has observed, privacy suffers from "an embarrassment of meanings." Privacy is far too vague a concept to guide adjudication and lawmaking, as abstract incantations of the importance of "privacy" do not fare well when pitted against more concretely stated countervailing interests. In 1960, the famous torts scholar William Prosser attempted to make sense of the landscape of privacy law by identifying four different interests. But Prosser focused only on tort law, and the law of information privacy is significantly more vast and complex, extending to Fourth Amendment law, the constitutional right to information privacy, evidentiary privileges, dozens of federal privacy statutes, and hundreds of state statutes. Moreover, Prosser wrote over 40 years ago, and new technologies have given rise to a panoply of new privacy harms. A new taxonomy to understand privacy violations is thus sorely needed. This Article develops a taxonomy to identify privacy problems in a comprehensive and concrete manner. It endeavors to guide the law toward a more coherent understanding of privacy and to serve as a framework for the future development of the field of privacy law.},
author = {Solove, Daniel J.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Solove - Unknown - A Taxonomy of Privacy.pdf:pdf},
issn = {00419907},
journal = {University of Pennsylvania Law Review},
number = {3},
pages = {477--564},
title = {{A taxonomy of privacy}},
volume = {154},
year = {2006}
}
@techreport{Guitierrez2013,
abstract = {The Federal Information Processing Standards (FIPS) Publication Series of the National Institute of Standards and Technology (NIST) is the official series of publications relating to standards and guidelines adopted and promulgated under the provisions of the Federal Information Security Management Act (FISMA) of 2002. Comments concerning FIPS publications are welcomed and should be addressed to the Director, Information Technology Laboratory, National Institute of Standards and Technology, 100 Bureau Drive, Stop 8900, Gaithersburg, MD 20899-8900.},
author = {Guitierrez, Carlos M. and Jeffrey, William and Furlani, Cita M.},
booktitle = {NIST},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guitierrez, Jeffrey, Furlani - 2013 - FIPS PUB 200 Minimum Security Requirements for Federal Information and Information Systems.pdf:pdf},
keywords = {FIPS 200,Minimum Security Requirements for Federal Informat,risk-assessment,security controls,security requirements},
title = {{FIPS PUB 200: Minimum Security Requirements for Federal Information and Information Systems}},
url = {http://csrc.nist.gov/publications/fips/fips200/FIPS-200-final-march.pdf},
year = {2013}
}
@misc{PrivacyAffa,
author = {{Privacy Affairs}},
title = {{GDPR Fines List: Find all GDPR fines {\&} detailed statistics}},
url = {https://www.privacyaffairs.com/gdpr-fines/},
year = {2020}
}
@book{Stallings2019,
author = {Stallings, William},
publisher = {Addison-Wesley},
title = {{Information Privacy Engineering and Privacy by Design: Understanding Privacy Threats, Technology, and Regulations Based on Standards and Best Practices}},
year = {2019}
}
@inproceedings{Venkatadri2018,
abstract = {Sites like Facebook and Google now serve as de facto data brokers, aggregating data on users for the purpose of implementing powerful advertising platforms. Historically, these services allowed advertisers to select which users see their ads via targeting attributes. Recently, most advertising platforms have begun allowing advertisers to target users directly by uploading the personal information of the users who they wish to advertise to (e.g., their names, email addresses, phone numbers, etc.); these services are often known as custom audiences. Custom audiences effectively represent powerful linking mechanisms, allowing advertisers to leverage any PII (e.g., from customer data, public records, etc.) to target users. In this paper, we focus on Facebook's custom audience implementation and demonstrate attacks that allow an adversary to exploit the interface to infer users' PII as well as to infer their activity. Specifically, we show how the adversary can infer users' full phone numbers knowing just their email address, determine whether a particular user visited a website, and de-anonymize all the visitors to a website by inferring their phone numbers en masse. These attacks can be conducted without any interaction with the victim(s), cannot be detected by the victim(s), and do not require the adversary to spend money or actually place an ad. We propose a simple and effective fix to the attacks based on reworking the way Facebook de-duplicates uploaded information. Facebook's security team acknowledged the vulnerability and has put into place a fix that is a variant of the fix we propose. Overall, our results indicate that advertising platforms need to carefully consider the privacy implications of their interfaces.},
author = {Venkatadri, Giridhari and Andreou, Athanasios and Liu, Yabing and Mislove, Alan and Gummadi, Krishna P. and Loiseau, Patrick and Goga, Oana},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
doi = {10.1109/SP.2018.00014},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Venkatadri et al. - 2018 - Privacy Risks with Facebook's PII-Based Targeting Auditing a Data Broker's Advertising Interface.pdf:pdf},
isbn = {9781538643525},
issn = {10816011},
keywords = {Data brokers,PII based targeting,advertising,attacks and defenses,privacy,targeted ad interfaces},
month = {jul},
pages = {89--107},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Privacy Risks with Facebook's PII-Based Targeting: Auditing a Data Broker's Advertising Interface}},
volume = {2018-May},
year = {2018}
}
@article{Ambreen2018,
abstract = {Requirements engineering (RE) being a foundation of software development has gained a great recognition in the recent era of prevailing software industry. A number of journals and conferences have published a great amount of RE research in terms of various tools, techniques, methods, and frameworks, with a variety of processes applicable in different software development domains. The plethora of empirical RE research needs to be synthesized to identify trends and future research directions. To represent a state-of-the-art of requirements engineering, along with various trends and opportunities of empirical RE research, we conducted a systematic mapping study to synthesize the empirical work done in RE. We used four major databases IEEE, ScienceDirect, SpringerLink and ACM and Identified 270 primary studies till the year 2012. An analysis of the data extracted from primary studies shows that the empirical research work in RE is on the increase since the year 2000. The requirements elicitation with 22 {\%} of the total studies, requirements analysis with 19 {\%} and RE process with 17 {\%} are the major focus areas of empirical RE research. Non-functional requirements were found to be the most researched emerging area. The empirical work in the sub-area of requirements validation and verification is little and has a decreasing trend. The majority of the studies (50 {\%}) used a case study research method followed by experiments (28 {\%}), whereas the experience reports are few (6 {\%}). A common trend in almost all RE sub-areas is about proposing new interventions. The leading intervention types are guidelines, techniques and processes. The interest in RE empirical research is on the rise as whole. However, requirements validation and verification area, despite its recognized importance, lacks empirical research at present. Furthermore, requirements evolution and privacy requirements also have little empirical research. These RE sub-areas need the attention of researchers for more empirical research. At present, the focus of empirical RE research is more about proposing new interventions. In future, there is a need to replicate existing studies as well to evaluate the RE interventions in more real contexts and scenarios. The practitioners' involvement in RE empirical research needs to be increased so that they share their experiences of using different RE interventions and also inform us about the current requirements-related challenges and issues that they face in their work.},
author = {Ambreen, Talat and Ikram, Naveed and Usman, Muhammad and Niazi, Mahmood},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ambreen et al. - 2018 - Empirical research in requirements engineering trends and opportunities.pdf:pdf},
journal = {Requirements Engineering},
keywords = {Evidence-based software engineering,Mapping study,Requirements engineering,Systematic review},
number = {1},
pages = {63--95},
title = {{Empirical research in requirements engineering: trends and opportunities}},
volume = {23},
year = {2018}
}
@article{Guo2020,
abstract = {Context: Modern software systems are deployed in sociotechnical settings, combining social entities (humans and organizations) with technical entities (software and devices). In such settings, on top of technical controls that implement security features of software, regulations specify how users should behave in security-critical situations. No matter how carefully the software is designed and how well regulations are enforced, such systems are subject to breaches due to social (user misuse) and technical (vulnerabilities in software) factors. Breach reports, often legally mandated, describe what went wrong during a breach and how the breach was remedied. However, breach reports are not formally investigated in current practice, leading to valuable lessons being lost regarding past failures. Objective: Our research aim is to aid security analysts and software developers in obtaining a set of legal, security, and privacy requirements, by developing a crowdsourcing methodology to extract knowledge from regulations and breach reports. Method: We present {\c{C}}orba, a methodology that leverages human intelligence via crowdsourcing, and extracts requirements from textual artifacts in the form of regulatory norms. We evaluate {\c{C}}orba on the US healthcare regulations from the Health Insurance Portability and Accountability Act (HIPAA) and breach reports published by the US Department of Health and Human Services (HHS). Following this methodology, we have conducted a pilot and a final study on the Amazon Mechanical Turk crowdsourcing platform. Results: {\c{C}}orba yields high quality responses from crowd workers, which we analyze to identify requirements for the purpose of complementing HIPAA regulations. We publish a curated dataset of the worker responses and identified requirements. Conclusions: The results show that the instructions and question formats presented to the crowd workers significantly affect the response quality regarding the identification of requirements. We have observed significant improvement from the pilot to the final study by revising the instructions and question formats. Other factors, such as worker types, breach types, or length of reports, do not have notable effect on the workers' performance. Moreover, we discuss other potential improvements such as breach report restructuring and text highlighting with automated methods.},
author = {Guo, Hui and Kafali, {\"{O}}zg{\"{u}}r and Jeukeng, Anne Liz and Williams, Laurie and Singh, Munindar P.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2020 - {\c{C}}orba crowdsourcing to obtain requirements from regulations and breaches.pdf:pdf},
journal = {Empirical Software Engineering},
keywords = {HIPAA,Regulatory norms,Sociotechnical systems},
number = {1},
pages = {532--561},
title = {{{\c{C}}orba: crowdsourcing to obtain requirements from regulations and breaches}},
volume = {25},
year = {2020}
}
@article{Ebrahimi2019,
abstract = {Mobile applications (apps) have become deeply personal, constantly demanding access to privacy-sensitive information in exchange for more personalized user experiences. Such privacy-invading practices have generated major multidimensional and unconventional privacy concerns among app users. To address these concerns, the research on mobile app privacy has experienced rapid growth over the past decade. In general, this line of research is aimed at systematically exposing the privacy practices of apps and proposing solutions to protect the privacy of mobile app users. In this survey paper, we conduct a systematic mapping study of 54 Software Engineering (SE) primary studies on mobile app privacy. Our objectives are to a) explore trends in SE app privacy research, b) categorize existing evidence, and c) identify potential directions for future research. Our results show that existing literature can be divided into four main categories: privacy policy, requirements, user perspective, and leak detection. Furthermore, our survey reveals an imbalance between these categories; majority of existing research focuses on proposing tools for detecting privacy leaks, with less studies targeting privacy requirements and policy and even less on user perspective. Finally, our survey exposes several gaps in existing research and suggests areas for improvement.},
author = {Ebrahimi, Fahimeh and Tushev, Miroslav and Mahmoud, Anas},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebrahimi, Tushev, Mahmoud - 2019 - Mobile App Privacy in Software Engineering Research A Systematic Mapping Study.pdf:pdf},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
keywords = {Index Terms-Privacy,mobile application,systematic mapping study},
number = {8},
title = {{Mobile App Privacy in Software Engineering Research: A Systematic Mapping Study}},
volume = {14},
year = {2019}
}
@article{Mihaylov2016a,
abstract = {Standards and regulations are difficult to understand and map to software, which makes compliance with them challenging to argue for software products and development process. This is problematic since lack of compliance may lead to issues with security, safety, and even to economic sanctions. An increasing number of applications (for example in healthcare) are expected to have to live up to regulatory requirements in the future, which will lead to more software development projects having to deal with such requirements. We present an approach that models regulations such that compliance arguments can be made in a principled way based on architectural requirements and architectural decisions. In particular, we discuss how one can form architectural requirements which are linked to regulatory texts. We then argue for completeness and correctness of this bi-directional link. We evaluate the approach on the migration of the telemedicine platform Net4Care to the cloud, where certain regulations (for example privacy) should be concerned. The approach has the potential to support simpler compliance argumentation with the eventual promise of safer and more secure applications.},
author = {Mihaylov, Boyan and Onea, Lucian and Hansen, Klaus Marius},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mihaylov, Onea, Hansen - 2016 - Architecture-based regulatory compliance argumentation.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Regulatory compliance,Software architecture,Software development},
pages = {1--30},
title = {{Architecture-based regulatory compliance argumentation}},
volume = {119},
year = {2016}
}
@inproceedings{Kasai2006,
abstract = {Personalized services can provide significant user benefits since they adapt their behavior to better support the user. Personalized services use a variety of data related to the user to decide their behavior. Thus personalized service needs a provisioning system that can collect the data that impacts service behavior and allows selection of the most appropriate service. However, in the coming ubiquitous environment, some data necessary for determining service behavior might be unavailable due to two possible reasons. One is that the data does not exit. The other is that the data exists but can not be accessed. For example, users do not want to disclose their personal information, and service providers do not also want to expose data related to their know-how in services. This paper describes a new service provisioning system for distributed personalization with private data protection. Specifically, the system selects applicable services by assessing how well each candidate service behaves when some data is missing. It then executes those selected services while hiding the users' and providers' private data in a distributed manner. We first summarize the requirements for a personalized service system, and introduce our fundamental policies for the system. The two main components of our system are then described in detail. One component is a service assessment mechanism that can judge if a service can work without data that can be used for adaptation. The second component is a service execution mechanism that can utilize private data while still ensuring privacy. This component divides service logic and executes divided logic where necessary data is available. The paper finally describes our prototype implementation and its performance evaluation results. {\textcopyright}2006 IEEE.},
author = {Kasai, Hiroyuki and Uchida, Wataru and Kurakake, Shoji},
booktitle = {Proceedings for ICPS:2006 International Conference on Pervasive Services},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasai, Uchida, Kurakake - 2006 - A service provisioning system for distributed personalization with private data protection.pdf:pdf},
keywords = {Bayesian network,Personalized service,Privacy protection,Rule conversion,Service assessment,Service rule},
pages = {163--172},
title = {{A service provisioning system for distributed personalization with private data protection}},
volume = {2006},
year = {2006}
}
@article{Guaman2020,
abstract = {Software Quality Control (SQC) techniques are widely used throughout the software development process with the objective of assessing and detecting anomalies that affect the quality of an information system. Privacy is one quality attribute of software systems for which several SQC techniques have been proposed in recent years. However, research has been carried out from different perspectives and, consequently, it has led to a growing body of knowledge scattered across different domains. To bridge this gap, we have carried out a systematic mapping study to provide practitioners and researchers with an overview of the state-of-the-art techniques to carry out software quality control of information systems focusing on aspects of privacy. Our results show a steady growth in the research efforts in this field. The European General Data Protection Regulation seems to have a significant influence on this growth, since 37{\%} of techniques that focus on assessing compliance derive their assessment criteria from this legal framework. The maturity of the techniques varies between the type of technique: Formal verification techniques exhibit the lowest level of maturity while the combination of techniques has demonstrated its successful application in real-world scenarios. The latter seems a promising avenue of research as it provides better results in terms of coverage, precision and effectiveness than the application of individual, isolated techniques. In this paper, we describe the existing SQC techniques focusing on privacy and provide a suitable basis for identifying future research directions.},
author = {Guaman, Danny S. and Alamo, Jose M.Del and Caiza, Julio C.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guaman, Alamo, Caiza - 2020 - A Systematic Mapping Study on Software Quality Control Techniques for Assessing Privacy in Information Sys.pdf:pdf},
journal = {IEEE Access},
keywords = {Data protection,information systems,mapping,privacy,software engineering,software quality control,systematic study},
pages = {74808--74833},
title = {{A Systematic Mapping Study on Software Quality Control Techniques for Assessing Privacy in Information Systems}},
volume = {8},
year = {2020}
}
@inproceedings{Wang2010,
abstract = {Fuzz testing has proven successful in finding security vulnerabilities in large programs. However, traditional fuzz testing tools have a well-known common drawback: they are ineffective if most generated malformed inputs are rejected in the early stage of program running, especially when target programs employ checksum mechanisms to verify the integrity of inputs. In this paper, we present TaintScope, an automatic fuzzing system using dynamic taint analysis and symbolic execution techniques, to tackle the above problem. TaintScope has several novel contributions: 1) TaintScope is the first checksum-aware fuzzing tool to the best of our knowledge. It can identify checksum fields in input instances, accurately locate checksum-based integrity checks by using branch profiling techniques, and bypass such checks via control flow alteration. 2) TaintScope is a directed fuzzing tool working at X86 binary level (on both Linux and Window). Based on fine-grained dynamic taint tracing, TaintScope identifies which bytes in a well-formed input are used in security-sensitive operations (e.g., invoking system/library calls) and then focuses on modifying such bytes. Thus, generated inputs are more likely to trigger potential vulnerabilities. 3) TaintScope is fully automatic, from detecting checksum, directed fuzzing, to repairing crashed samples. It can fix checksum values in generated inputs using combined concrete and symbolic execution techniques. We evaluate TaintScope on a number of large real-world applications. Experimental results show that TaintScope can accurately locate the checksum checks in programs and dramatically improve the effectiveness of fuzz testing. TaintScope has already found 27 previously unknown vulnerabilities in several widely used applications, including Adobe Acrobat, Google Picasa, Microsoft Paint, and ImageMagick. Most of these severe vulnerabilities have been confirmed by Secunia and oCERT, and assigned CVE identifiers (such as CVE-20091882, CVE-2009-2688). Corresponding patches from vendors are released or in progress based on our reports. {\textcopyright}2010 IEEE.},
author = {Wang, Tielei and Wei, Tao and Gu, Guofei and Zou, Wei},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2010 - TaintScope A checksum-aware directed fuzzing tool for automatic software vulnerability detection.pdf:pdf},
keywords = {Dynamic taint analysis,Fuzzirig,Symbolic execution},
pages = {497--512},
title = {{TaintScope: A checksum-aware directed fuzzing tool for automatic software vulnerability detection}},
year = {2010}
}
@inproceedings{Calandrino2011,
abstract = {Many commercial websites use recommender systems to help customers locate products and content. Modern recommenders are based on collaborative filtering: they use patterns learned from users' behavior to make recommendations, usually in the form of related-items lists. The scale and complexity of these systems, along with the fact that their outputs reveal only relationships between items (as opposed to information about users), may suggest that they pose no meaningful privacy risk. In this paper, we develop algorithms which take a moderate amount of auxiliary information about a customer and infer this customer's transactions from temporal changes in the public outputs of a recommender system. Our inference attacks are passive and can be carried out by any Internet user. We evaluate their feasibility using public data from popular websites Hunch, Last.fm, LibraryThing, and Amazon. {\textcopyright} 2011 IEEE.},
author = {Calandrino, Joseph A. and Kilzer, Ann and Narayanan, Arvind and Felten, Edward W. and Shmatikov, Vitaly},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Calandrino et al. - 2011 - You might also like Privacy risks of collaborative filtering.pdf:pdf},
pages = {231--246},
title = {{"You might also like:" Privacy risks of collaborative filtering}},
year = {2011}
}
@misc{Nortona,
author = {Stouffer, Clare},
booktitle = {Norton},
title = {{What is social engineering?}},
url = {https://us.norton.com/internetsecurity-emerging-threats-what-is-social-engineering.html},
urldate = {2021-08-22},
year = {2021}
}
@inproceedings{Tabassum,
abstract = {Smart homes are more connected than ever before, with a variety of commercial devices available. The use of these devices introduces new security and privacy risks in the home, and needs for helping users to understand and mitigate those risks. However, we still know little about how everyday users understand the data practices of smart home devices, and their concerns and behaviors regarding those practices. To bridge this gap, we conducted a semi-structured interview study with 23 smart home users to explore what people think about smart home device data collection, sharing, and usage practices; how that knowledge affects their perceived risks of security and privacy; and the actions they take to resolve those risks. Our results reveal that while people are uncertain about manufacturers' data practices, users' knowledge of their smart home does not strongly influence their threat models and protection behaviors. Instead, users' perceptions and concerns are largely shaped by their experiences in other computing contexts and with organizations. Based on our findings, we provide several recommendations for policymakers, researchers and designers to contribute to users' risk awareness and security and privacy practices in the smart home.},
author = {Tabassum, Madiha and Kosi{\'{n}}ski, Tomasz and Lipford, Heather Richter},
booktitle = {Proceedings of the 15th Symposium on Usable Privacy and Security, SOUPS 2019},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tabassum, Kosi{\'{n}}ski, Lipford - 2019 - I don't own the data End user perceptions of smart home device data practices and risks.pdf:pdf},
pages = {435--450},
title = {{"I don't own the data": End user perceptions of smart home device data practices and risks}},
year = {2019}
}
@inproceedings{Some2019,
abstract = {Browser extensions are third party programs, tightly integrated to browsers, where they execute with elevated privileges in order to provide users with additional functionalities. Unlike web applications, extensions are not subject to the Same Origin Policy (SOP) and therefore can read and write user data on any web application. They also have access to sensitive user information including browsing history, bookmarks, credentials (cookies) and list of installed extensions. They have access to a permanent storage in which they can store data as long as they are installed in the user's browser. They can trigger the download of arbitrary files and save them on the user's device. For security reasons, browser extensions and web applications are executed in separate contexts. Nonetheless, in all major browsers, extensions and web applications can interact by exchanging messages. Through these communication channels, a web application can exploit extension privileged capabilities and thereby access and exfiltrate sensitive user information. In this work, we analyzed the communication interfaces exposed to web applications by Chrome, Firefox and Opera browser extensions. As a result, we identified many extensions that web applications can exploit to access privileged capabilities. Through extensions' APIS, web applications can bypass SOP and access user data on any other web application, access user credentials (cookies), browsing history, bookmarks, list of installed extensions, extensions storage, and download and save arbitrary files in the user's device. Our results demonstrate that the communications between browser extensions and web applications pose serious security and privacy threats to browsers, web applications and more importantly to users. We discuss countermeasures and proposals, and believe that our study and in particular the tool we used to detect and exploit these threats, can be used as part of extensions review process by browser vendors to help them identify and fix the aforementioned problems in extensions.},
author = {Some, Doliere Francis},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Some - 2019 - EmPoWeb Empowering web applications with browser extensions.pdf:pdf},
keywords = {-Attacks-and-defenses,-Malware-and-unwanted-software,-Mobile-and-Web-security-and-privacy,-Privacy-technologies-and-mechanisms,Application-security},
month = {may},
pages = {227--245},
title = {{EmPoWeb: Empowering web applications with browser extensions}},
volume = {2019-May},
year = {2019}
}
@inproceedings{Acar2017,
abstract = {Through their third-party app installation decisions, users are frequently triggering interdependent privacy consequences by sharing personal information of their friends who are unable to control these information flows. With our study, we aim to quantify the value which app users attribute to their friends' information (i.e., value of interdependent privacy) and to understand how this valuation is affected by two factors: sharing anonymity (i.e., whether disclosure of friends' information is anonymous), and context relevance (i.e., whether friends' information is necessary for apps' functionality). Specifically, we conduct a between-subject, choice-based conjoint analysis study with 4 treatment conditions (2 sharing anonymity × 2 context relevance). Our study confirms the important roles that sharing anonymity and context relevance play in the process of interdependent privacy valuation. In addition, we also investigate how other factors, e.g., individuals' personal attributes and experiences, affect interdependent privacy valuations by applying structural equation modeling analysis. Our research findings yield design implications as well as contribute to policy discussions to better account for the problem of interdependent privacy.},
author = {Pu, Yu and Grossklags, Jens},
booktitle = {Proceedings of the 13th Symposium on Usable Privacy and Security, SOUPS 2017},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pu, Grossklags - 2019 - Valuating friends' privacy Does anonymity of sharing personal data matter.pdf:pdf},
pages = {339--355},
title = {{Valuating friends' privacy: Does anonymity of sharing personal data matter?}},
url = {https://www.usenix.org/conference/soups2017/technical-sessions/presentation/acar},
year = {2019}
}
@article{Chou2004,
abstract = {The role-based access control (RBAC) approach has been recognized as useful in information security and many RBAC models have been proposed. Current RBAC researches focus on developing new models or enhancing existing models. In our research, we developed an RBAC model that can be embedded in object-oriented systems to control information flows (i.e. to protect privacy) within the systems. This paper proposes the model. The model, which is named OORBAC, is an extension of RBAC96. OORBAC offers the following features: (a) precisely control information flows among objects, (b) control method invocation through argument sensitivity, (c) allow purpose-oriented method invocation and prevent leakage within an object, (d) precisely control write access, and (e) avoid Trojan horses. We implemented a prototype for OORBAC using JAVA as the target language. The implementation resulted in a language named OORBACL, which can be used to implement secure applications. We evaluated OORBAC using experiments. The evaluation results are also shown in this paper. {\textcopyright} 2002 Elsevier Inc. All rights reserved.},
author = {Chou, Shih Chien},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chou - 2004 - Embedding role-based access control model in object-oriented systems to protect privacy.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Information flow control,Object-oriented systems,Protect privacy,Security},
number = {1-2},
pages = {143--161},
title = {{Embedding role-based access control model in object-oriented systems to protect privacy}},
volume = {71},
year = {2004}
}
@misc{CWEschema2021,
author = {{CWE Team}},
booktitle = {Common Weakness Enumeration},
title = {{CWE - Schema Documentation - Schema Version 6.5}},
url = {https://cwe.mitre.org/documents/schema/},
urldate = {2021-08-30},
year = {2021}
}
@inproceedings{Treu2007,
abstract = {Being increasingly equipped with highly-accurate positioning technologies, today's mobile phones enable their owners to transmit their current position over the cellular network and share it with others. So-called location-based community services make use of this possibility, for example for locating friends or family members. Such services give target persons control about the way location data may be accessed by others. So far, this is done by the target explicitly granting or denying permissions through authorization policies or ad-hoc authorization. Unfortunately, apart from bringing along high management effort, the concept of explicit authorization in such a privacy-sensitive application entails the disadvantage of social difficulties. In this paper we introduce the concept of implicit authorization, where an inquirer is granted access to the required information as the result of a certain activity of the target that is not solely dedicated to managing her own location information. In the proposed realization of implicit authorization, access to one's own information is granted implicitely by accessing the information of another person. The approach is analyzed theoretically and computationally. It turns out that management overhead is minimized while guaranteeing better social acceptability. {\textcopyright} 2007 IEEE.},
author = {Treu, Georg and Fuchs, Florian and Dargatz, Christiane},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Treu, Fuchs, Dargatz - 2007 - Implicit authorization for accessing location data in a social context.pdf:pdf},
pages = {263--270},
title = {{Implicit authorization for accessing location data in a social context}},
year = {2007}
}
@inproceedings{Reinheimer2020b,
abstract = {Smart-home devices are becoming increasingly ubiquitous and interconnected with other devices and services, such as phones, fitness trackers, cars, and social media accounts. Built-in connections between these services are still emerging, but end-user-programming tools such as If-This-Then-That (IFTTT) have existed for almost a decade, allowing users to create rules (called applets in IFTTT) that dictate interactions between devices and services. Previous work found potential secrecy or integrity violations in many applets, but did so without examining how individual users interact with the service. In this work, we study the risks of real-world use of IFTTT by collecting and analyzing 732 applets installed by 28 participants and participants' responses to several survey questions. We found that significantly fewer applets than previously thought pose realistic secrecy or integrity risks to the users who install them. Consistent with this finding, participants were generally not concerned about potential harms, even when these were explained to them. However, examining participants' applets led us to identify several new types of privacy risks, which challenge some assumptions inherent in previous analyses that focus on secrecy and integrity risks. For example, we found that many applets involve monitoring incidental users: family, friends, and neighbors who may interact with someone else's smart-home devices, possibly without realizing it. We discuss what our findings imply for automatically identifying potentially harmful applets.},
author = {Cobb, Camille and Surbatovich, Milijana and Kawakami, Anna and Sharif, Mahmood and Bauer, Lujo and Das, Anupam and Jia, Limin},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cobb et al. - 2020 - How risky are real users' IFTTT applets.pdf:pdf},
pages = {505--529},
title = {{How risky are real users' IFTTT applets?}},
year = {2020}
}
@article{Wieringa2006,
author = {Wieringa, Roel and Maiden, Neil and Mead, Nancy and Rolland, Colette},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wieringa et al. - 2006 - Requirements engineering paper classification and evaluation criteria A proposal and a discussion.pdf:pdf},
journal = {Requirements Engineering},
keywords = {Paper classification,Paper evaluation criteria,Requirements engineering research,Research methods},
number = {1},
pages = {102--107},
title = {{Requirements engineering paper classification and evaluation criteria: A proposal and a discussion}},
volume = {11},
year = {2006}
}
@inproceedings{Bhatia2018a,
abstract = {Companies that collect personal information online often maintain privacy policies that are required to accurately reflect their data practices and privacy goals. To be comprehensive and flexible for future practices, policies contain ambiguity that summarize practices over multiple types of products and business contexts. Ambiguity in data practice descriptions undermines policies as an effective way to communicate system design choices to users, and as a reliable regulatory mechanism. In this paper, we report an investigation to identify incompleteness by representing data practice descriptions as semantic frames. The approach is a grounded analysis to discover which data actions and semantic roles correspond are needed to construct complete data practice descriptions. Our results include 281 data action instances obtained from 202 manually annotated statements across five privacy policies. Therein, we identified 878 instances of 17 types of semantic roles. Incomplete data practice descriptions undermine user comprehension, and can affect the user's perceived privacy risk, which we measure using factorial vignette surveys. We observed that user perception of risk decreases when two roles are present in a statement: the condition under which a data action is performed, and the purpose for which the user's information is used.},
author = {Bhatia, Jaspreet and Breaux, Travis D.},
booktitle = {Proceedings - 2018 IEEE 26th International Requirements Engineering Conference, RE 2018},
doi = {10.1109/RE.2018.00025},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatia, Breaux - 2018 - Semantic incompleteness in privacy policy goals.pdf:pdf},
isbn = {9781538674185},
keywords = {Natural language processing,Privacy,Privacy risk,Semantic frames,Semantic roles},
month = {oct},
pages = {159--169},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Semantic incompleteness in privacy policy goals}},
year = {2018}
}
@inproceedings{Zhang2020a,
abstract = {Mobile application (app) developers commonly utilize analytic services to analyze their app users' behavior to support debugging, improve service quality, and facilitate advertising. Anonymization and aggregation can reduce the sensitivity of such behavioral data, therefore analytic services often encourage the use of such protections. However, these protections are not directly enforced so it is possible for developers to misconfigure the analytic services and expose personal information, which may cause greater privacy risks. Since people use apps in many aspects of their daily lives, such misconfigurations may lead to the leaking of sensitive personal information such as a users' real-time location, health data, or dating preferences. To study this issue and identify potential privacy risks due to such misconfigurations, we developed a semiautomated approach, Privacy-Aware Analytics Misconfiguration Detector (PAMDroid), which enables our empirical study on misconfigurations of analytic services. This paper describes a study of 1,000 popular apps using top analytic services in which we found misconfigurations in 120 apps. In 52 of the 120 apps, misconfigurations lead to a violation of either the analytic service providers' terms of service or the app's own privacy policy.},
author = {Zhang, Xueling and Wang, Xiaoyin and Slavin, Rocky and Breaux, Travis and Niu, Jianwei},
booktitle = {Proceedings - International Conference on Software Engineering},
keywords = {Analytic services,Configuration,Mobile application,Privacy,Program analysis},
pages = {1572--1583},
title = {{How does misconfiguration of analytic services compromise mobile privacy}},
year = {2020}
}
@inproceedings{Vora2018,
abstract = {Mobile medicine and health care have been adopted on a very large scale with support from the influx of medical devices and increased usability of remote health services. These are combined with an approachable interest of the patients and a readily approachable conscience about their healthcare. This leads to a huge set of medical data. These data sets require secure transfer, archival and access. In this study, we have proposed an efficient approach to preserve the identity and also protect the privacy of clinical data using highly effective encryption scheme. Moreover, we have also discussed an authorization framework using access of varying degrees. Medical records are often accessed by various entities with varying degrees of authorization. In this study, we have implemented the ATT scheme for managing the access control mechanism of patients data. Further, encryption is undertaken using ARCANA, that provides hierarchically satisfied access to various data resources. It utilizes the XACML access model to formulate the access control framework. The primary reason for using this model is the regulation to access the data through ATT based on XACML policies. In addition to this, the encrypting of medical data using various authorization techniques have been required for the proper data access regulation. Which may impact trust of the users in the e-health paradigm and in turn increase the large-scale usability.},
author = {Vora, Jayneel and Italiya, Prit and Tanwar, Sudeep and Tyagi, Sudhanshu and Kumar, Neeraj and Obaidat, M. S. and Hsiao, K. F.},
booktitle = {CITS 2018 - 2018 International Conference on Computer, Information and Telecommunication Systems},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vora et al. - 2018 - Ensuring privacy and security in E-health records.pdf:pdf},
keywords = {Anonymity,Decryption,Encryption,Policy,Privacy,Security,e-health},
title = {{Ensuring privacy and security in E-health records}},
year = {2018}
}
@article{Solove2006a,
abstract = {Privacy is a concept in disarray. Nobody can articulate what it means. As one commentator has observed, privacy suffers from "an embarrassment of meanings." Privacy is far too vague a concept to guide adjudication and lawmaking, as abstract incantations of the importance of "privacy" do not fare well when pitted against more concretely stated countervailing interests. In 1960, the famous torts scholar William Prosser attempted to make sense of the landscape of privacy law by identifying four different interests. But Prosser focused only on tort law, and the law of information privacy is significantly more vast and complex, extending to Fourth Amendment law, the constitutional right to information privacy, evidentiary privileges, dozens of federal privacy statutes, and hundreds of state statutes. Moreover, Prosser wrote over 40 years ago, and new technologies have given rise to a panoply of new privacy harms. A new taxonomy to understand privacy violations is thus sorely needed. This Article develops a taxonomy to identify privacy problems in a comprehensive and concrete manner. It endeavors to guide the law toward a more coherent understanding of privacy and to serve as a framework for the future development of the field of privacy law.},
author = {Solove, Daniel J.},
journal = {University of Pennsylvania Law Review},
number = {3},
pages = {477--564},
title = {{A taxonomy of privacy}},
volume = {154},
year = {2006}
}
@article{Lin2016b,
abstract = {In the cloud computing environment, since data owners worry about private information in their data being disclosed without permission, they try to retain the knowledge within the data, while applying privacy-preserving techniques to the data. In the past, a data perturbation approach was commonly used to modify the original data content, but it also results in data distortion, and hence leads to significant loss of knowledge within the data. To solve this problem, this study introduced the concept of reversible integer transformation in the image processing domain and developed a Reversible Data Transform (RDT) algorithm that can disrupt and restore data. In the RDT algorithm, using an adjustable weighting mechanism, the degree of data perturbation was adjusted to increase the flexibility of privacy-preserving. In addition, it allows the data to be embedded with a watermark, in order to identify whether the perturbed data has been tampered with. Experimental results show that, compared with the existing algorithms, RDT has better knowledge reservation and is better in terms of effectively reducing information loss and privacy disclosure risk. In addition, it has a high watermark payload.},
author = {Lin, Chen Yi},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin - 2016 - A reversible data transform algorithm using integer transform for privacy-preserving data mining.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Cloud computing,Privacy-preserving,Reversible data hiding},
pages = {104--112},
title = {{A reversible data transform algorithm using integer transform for privacy-preserving data mining}},
volume = {117},
year = {2016}
}
@inproceedings{Wuyts2009,
abstract = {Privacy is gaining importance since more and more data becomes digitalized. There is also a growing interest from the security community because of the existing synergy between security and privacy. Unfortunately, the privacy development life cycle is less advanced than the security one. A clear classification into different objectives is not available yet. This paper attempts to scope the privacy landscape for software engineering by proposing an operational definition for privacy and by describing a privacy taxonomy. The taxonomy is rooted in the definition and presents a classification of privacy objectives, which correspond to the developer's goals. Each objective can be achieved by one or more strategies. As a validation for the taxonomy, existing privacy solutions are matched to each strategy. {\textcopyright} 2009 IEEE.},
author = {Wuyts, Kim and Scandariato, Riccardo and {De Decker}, Bart and Joosen, Wouter},
booktitle = {Proceedings - International Conference on Availability, Reliability and Security, ARES 2009},
doi = {10.1109/ARES.2009.51},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wuyts et al. - 2009 - Linking privacy solutions to developer goals.pdf:pdf},
isbn = {9780769535647},
pages = {847--852},
title = {{Linking privacy solutions to developer goals}},
year = {2009}
}
@inproceedings{Avdiienko2015a,
abstract = {When a user downloads an Android application from a market, she does not know much about its actual behavior. A brief description, a set of screenshots, and the list of permissions, which give a high level intuition of what the application might be doing, are all the user sees before installing and running the application on his device. These elements are not enough to decide whether the application is secure, and for sure they do not indicate whether it might violate the user's privacy by leaking some sensitive data. The goal of my thesis is to employ both static and dynamic taint analyses to gather information on how Android applications use sensitive data. The main hypothesis of this work is that malicious and benign mobile applications differ in how they use sensitive data, and consequently information flow can be used effectively to identify malware.},
author = {Avdiienko, Vitalii},
booktitle = {Proceedings - International Conference on Software Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Avdiienko - 2015 - Mining Patterns of Sensitive Data Usage(2).pdf:pdf},
pages = {891--894},
title = {{Mining Patterns of Sensitive Data Usage}},
volume = {2},
year = {2015}
}
@article{Shaw,
abstract = {Physics, biology, and medicine have well-refined public explanations of their research processes. Even in simplified form, these provide guidance about what counts as "good research" both inside and outside the field. Software engineering has not yet explicitly identified and explained either our research processes or the ways we recognize excellent work. Science and engineering research fields can be characterized in terms of the kinds of questions they find worth investigating, the research methods they adopt, and the criteria by which they evaluate their results. I will present such a characterization for software engineering, showing the diversity of research strategies and the way they shift as ideas mature. Understanding these strategies should help software engineers design research plans and report the results clearly; it should also help explain the character of software engineering research to computer science at large and to other scientists. {\textcopyright} 2002 Springer-Verlag.},
author = {Shaw, Mary},
journal = {International Journal on Software Tools for Technology Transfer},
number = {1},
pages = {1--7},
title = {{What makes good research in software engineering?}},
url = {https://www.cs.cmu.edu/{~}Compose/ftp/shaw-fin-etaps.pdf},
volume = {4},
year = {2002}
}
@inproceedings{Reinheimer2020a,
abstract = {Cloud Office suites such as Google Docs or Microsoft Office 365 are widely used and introduce security and privacy risks to documents and sensitive user information. Users may not know how, where and by whom their documents are accessible and stored, and it is currently unclear how they understand and mitigate risks. We conduct surveys with 200 cloud office users from the U.S. and Germany to investigate their experiences and behaviours with cloud office suites. We explore their security and privacy perceptions and expectations, as well as their intuitions for how cloud office suites should ideally handle security and privacy. We find that our participants seem to be aware of basic general security implications, storage models, and access by others, although some of their threat models seem underdeveloped, often due to lacking technical knowledge. Our participants have strong opinions on how comfortable they are with the access of certain parties, but are somewhat unsure about who actually has access to their documents. Based on our findings, we distill recommendations for different groups associated with cloud office suites, which can help inform future standards, regulations, implementations, and configuration options.},
author = {Wermke, Dominik and Huaman, Nicolas and Stransky, Christian and Busch, Niklas and Acar, Yasemin and Fahl, Sascha},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wermke et al. - 2020 - Cloudy with a chance of misconceptions Exploring users' perceptions and expectations of security and privacy in c.pdf:pdf},
pages = {359--378},
title = {{Cloudy with a chance of misconceptions: Exploring users' perceptions and expectations of security and privacy in cloud office suites}},
year = {2020}
}
@article{Antn2004,
abstract = {The increasing use of personal information on web-based applications can result in unexpected disclosures. Consumers often have only the stated website policies as a guide to how their information is used, and thus on which to base their browsing transaction decisions. However, each policy is different, and it is difficult -- if not impossible -- for the average user to compare and comprehend these policies. This paper presents a taxonomy of privacy requirements for websites. Using goal-mining, the extraction of pre-requirements goals from post-requirements text artefacts, we analysed an initial set of Internet privacy policies to develop the taxonomy. This taxonomy was then validated during a second goal extraction exercise, involving privacy policies from a range of health care related websites. This validation effort enabled further refinement to the taxonomy, culminating in two classes of privacy requirements: protection goals and vulnerablities. Protection goals express the desired protection of consumer privacy rights, whereas vulnerabilities describe requirements that potentially threaten consumer privacy. The identified taxonomy categories are useful for analysing implicit internal conflicts within privacy policies, the corresponding websites, and their manner of operation. These categories can be used by website designers to reduce website privacy vulnerabilities and ensure that their stated and actual policies are consistent with each other. The same categories can be used by customers to evaluate and understand policies and their limitations. Additionally, the policies have potential use by third-party evaluators of site policies and conflicts.},
author = {Ant{\'{o}}n, Annie I. and Earp, Julia B.},
file = {:C$\backslash$:/Users/ps642/Downloads/6-A requirements taxonomy for reducing Web site privacy vulnerabilities (1).pdf:pdf},
journal = {Requirements Engineering},
keywords = {privacy requirements {\ae} security,requirements},
number = {3},
pages = {169--185},
title = {{A requirements taxonomy for reducing Web site privacy vulnerabilities}},
volume = {9},
year = {2004}
}
@inproceedings{Gorawski2007,
abstract = {Both transactional and analytical systems store data, which being accessible to unauthorized persons may result in privacy violation. This issue has become especially important nowadays, due to more restrictive legislation concerning personal data protection and preserving data privacy. We introduce relation decomposition as a method to preserve the data confidentiality in distributed spatial data warehouses. Data separation between nodes of distributed system can easily protect data privacy without requiring encrypting sensitive data. Using the relation decomposition strongly reduces the possibility of a disclosure of private information contained in data warehouse. The article presents how specified secure policy can be implemented into the data warehouse system as well as how analytical applications can retrieve protected data from the database. Finally, we present test results verifying efficiency of the latter operations including comparison between relation decomposition and the most popular method of preserving data privacy i.e. data encryption using symmetric encryption algorithms. {\textcopyright} 2007 IEEE.},
author = {Gorawski, Marcin and Bularz, Jakub},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorawski, Bularz - 2007 - Protecting private information by data separation in distributed spatial data warehouse.pdf:pdf},
pages = {837--844},
title = {{Protecting private information by data separation in distributed spatial data warehouse}},
year = {2007}
}
@inproceedings{Franz2006,
abstract = {Access control is necessary to prevent illegal accesses to shared resources. Within eLearning, access control is required in order to protect provided contents and services as well as user data. Usually, access rights are assigned to users of a system. However, in a system that applies Privacy-Enhancing Identity Management (PIM) common approaches cannot be directly utilized since users do not act under fix login names. Within this paper, we want to discuss how protection of contents as well as of user data can be realized in such an environment. The context of our work is the eLearning application BluES'n1 which additionally aims at providing users a flexible working environment. All functionality needed for realizing access control is provided by a PIM-aware platform which is currently developed within the European project PRIME2. {\textcopyright} 2006 IEEE.},
author = {Franz, Elke and Wahrig, Hagen and Boettcher, Alexander and Borcea-Pfitzmann, Katrin},
booktitle = {Proceedings - First International Conference on Availability, Reliability and Security, ARES 2006},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Franz et al. - 2006 - Access control in a privacy-aware eLearning environment.pdf:pdf},
pages = {879--886},
title = {{Access control in a privacy-aware eLearning environment}},
volume = {2006},
year = {2006}
}
@article{Viera2005,
abstract = {Items such as physical exam findings, radiographic interpretations, or other diagnostic tests often rely on$\backslash$r$\backslash$nsome degree of subjective interpretation by observers. Studies that measure the agreement between two or$\backslash$r$\backslash$nmore observers should include a statistic that takes into account the fact that observers will sometimes$\backslash$r$\backslash$nagree or disagree simply by chance. The kappa statistic (or kappa coefficient) is the most commonly used$\backslash$r$\backslash$nstatistic for this purpose. A kappa of 1 indicates perfect agreement, whereas a kappa of 0 indicates agreement$\backslash$r$\backslash$nequivalent to chance. A limitation of kappa is that it is affected by the prevalence of the finding under$\backslash$r$\backslash$nobservation. Methods to overcome this limitation have been described.$\backslash$r$\backslash$n},
author = {Viera, Anthony J and Garrett, Joanne M},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Viera, Garrett - 2005 - Understanding interobserver agreement the kappa statistic.pdf:pdf},
journal = {Family Medicine},
number = {5},
pages = {360--363},
title = {{Understanding interobserver agreement: the kappa statistic}},
volume = {37},
year = {2005}
}
@misc{OWASPsurvey,
author = {{The OWASP Foundation}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The OWASP Foundation - 2015 - OWASP Top 10 Privacy Risks Survey.pdf:pdf},
title = {{OWASP Top 10 Privacy Risks Survey}},
urldate = {2021-08-22},
year = {2015}
}
@misc{AppleiOS2019,
author = {{Apple Inc.}},
booktitle = {Apple Support},
title = {{About the security content of iOS 12.2 - Apple Support}},
url = {https://support.apple.com/en-gb/HT209599},
urldate = {2021-08-30},
year = {2019}
}
@techreport{Bloom2022,
author = {Bloom, Cara},
booktitle = {2022 USENIX Conference on Privacy Engineering Practice and Respect},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloom - 2022 - Privacy Threat Modeling.pdf:pdf},
title = {{Privacy Threat Modeling}},
year = {2022}
}
@article{NIST2020,
abstract = {This publication describes the voluntary NIST Privacy Framework: A Tool for Improving Privacy through Enterprise Risk Management (Version 1.0). The Privacy Framework is a tool developed in collaboration with stakeholders intended to help organizations identify and manage privacy risk to build innovative products and services while protecting individuals' privacy. The Privacy Framework provides a flexible, risk- and outcome-based approach, intended to be widely usable by organizations of all sizes and agnostic to any particular technology, sector, law, or jurisdiction. The Privacy Framework follows the structure of the Framework for Improving Critical Infrastructure Cybersecurity to facilitate the use of both frameworks together. Complete information about the Privacy Framework is available at https://www.nist.gov/privacyframework.},
author = {{National Institute of Standards and Technolgy}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Institute of Standards - 2020 - NIST PRIVACY FRAMEWORK A TOOL FOR IMPROVING PRIVACY THROUGH ENTERPRISE RISK MANAGEMENT, VERSION 1.0.pdf:pdf},
journal = {NIST Special Publication},
keywords = {privacy,privacy engineering,privacy framework,risk management},
pages = {43},
title = {{NIST Privacy Framework: a tool for improving privacy through enterprise risk management}},
url = {https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.01162020.pdf},
year = {2020}
}
@inproceedings{De2016,
abstract = {To carry out a true privacy risk analysis and go beyond a traditional security analysis, it is essential to distinguish the notions of feared events and their impacts, called «privacy harms» here, and to establish a link between them. In this paper, we provide a clear relationship among harms, feared events, privacy weaknesses and risk sources and describe their use in the analysis of smart grid systems. This work also lays the foundation for a more systematic and rigorous approach to privacy risk assessment.},
author = {De, Sourya Joyee and Metayer, Daniel Le},
booktitle = {Proceedings - 2016 IEEE Symposium on Security and Privacy Workshops, SPW 2016},
keywords = {privacy harms,privacy risk analysis,smart grids},
pages = {58--65},
title = {{Privacy Harm Analysis: A Case Study on Smart Grids}},
year = {2016}
}
@article{Hanif2021,
abstract = {The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests' taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95{\%} of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.},
author = {Hanif, Hazim and {Md Nasir}, Mohd Hairul Nizam and {Ab Razak}, Mohd Faizal and Firdaus, Ahmad and Anuar, Nor Badrul},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanif et al. - 2021 - The rise of software vulnerability Taxonomy of software vulnerabilities detection and machine learning approaches.pdf:pdf},
journal = {Journal of Network and Computer Applications},
keywords = {Computer security,Deep learning,Machine learning,Software security,Software vulnerability detection},
pages = {103009},
title = {{The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches}},
volume = {179},
year = {2021}
}
@article{Yang2016b,
abstract = {Nowadays, cloud storage service has been widely adopted by diverse organizations, through which users can conveniently share data with others. For security consideration, previous public auditing schemes for shared cloud data concealed the identities of group members. However, the unconstrained identity anonymity will lead to a new problem, that is, a group member can maliciously modify shared data without being identified. Since uncontrolled malicious modifications may wreck the usability of the shared data, the identity traceability should also be retained in data sharing. In this paper, we propose an efficient public auditing solution that can preserve the identity privacy and the identity traceability for group members simultaneously. Specifically, we first design a new framework for data sharing in cloud, and formalize the definition of the public auditing scheme for shared cloud data supporting identity privacy and traceability. And then we construct such a scheme, in which a group manager is introduced to help members generate authenticators to protect the identity privacy and two lists are employed to record the members who perform the latest modification on each block to achieve the identity traceability. Besides, the scheme also achieves data privacy during authenticator generation by utilizing blind signature technique. Based on the proposed scheme, we further design an auditing system for practical scenarios. Finally, we prove the proposed scheme is secure based on several security requirements, and justify its performance by concrete implementations.},
author = {Yang, Guangyang and Yu, Jia and Shen, Wenting and Su, Qianqian and Fu, Zhangjie and Hao, Rong},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2016 - Enabling public auditing for shared data in cloud storage supporting identity privacy and traceability.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Cloud storage,Identity traceability,Public auditing},
pages = {130--139},
title = {{Enabling public auditing for shared data in cloud storage supporting identity privacy and traceability}},
volume = {113},
year = {2016}
}
@inproceedings{Lucia2012,
abstract = {High-quality test data that is useful for effective testing is often available on users' site. However, sharing data owned by users with software vendors may raise privacy concerns. Techniques are needed to enable data sharing among data owners and the vendors without leaking data privacy. Evolving programs bring additional challenges because data may be shared multiple times for every version of a program. When multiple versions of the data are crossreferenced, private information could be inferred. Although there are studies addressing the privacy issue of data sharing for testing and debugging, little work has explicitly addressed the challenges when programs evolve. In this paper, we examine kb-anonymity that is recently proposed for anonymizing data for a single version of a program, and identify a potential privacy risk if it is repeatedly applied for evolving programs. We propose kb e- anonymity to address the insufficiencies of kb-anonymity and evaluate our model on three Java programs. We demonstrate that kb e-anonymity can successfully address the potential risk of kb-anonymity, maintain sufficient path coverage for testing, and be as efficient as kb-anonymity. Copyright 2012 ACM.},
author = {Lucia and Lo, David and Jiang, Lingxiao and Budi, Aditya},
booktitle = {2012 27th IEEE/ACM International Conference on Automated Software Engineering, ASE 2012 - Proceedings},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucia et al. - 2012 - Kb e-anonymity Test data anonymization for evolving programs.pdf:pdf},
keywords = {Behavior preservation,K-anonymity,Privacy preservation,Testing and debugging},
pages = {262--265},
title = {{Kb e-anonymity: Test data anonymization for evolving programs}},
year = {2012}
}
@misc{APA,
author = {{Federal Register of Legislation}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Federal Register of Legislation - 2017 - Privacy Act 1988.pdf:pdf},
number = {119},
title = {{Privacy Act 1988}},
url = {https://www.legislation.gov.au/Details/C2016C00979},
year = {2017}
}
@inproceedings{Li2017,
abstract = {Software vulnerability remains a serious challenge to the software engineering domain over the past decade as a result of the recent technological advancement in information systems. The rapid development in software applications and failure on the part of system developers to properly analyze program codes before been released to the market increases the chance for data breaches. It is a known fact that most system failures are as a result of bugs and errors detected in software applications. Although code errors significantly affect software quality, there is no effective method that can be used in eliminating software errors to improve its reliability. Data Mining and its related algorithms are an active area which can successfully be applied in analyzing software vulnerability. However the concept of applying data mining techniques has not been empirically proven as an effective method for obtaining the essential characteristics of software vulnerability. To investigate this effect, we propose a vulnerability mining algorithm to analyze and obtain the essential characteristics of Software vulnerability based data mining techniques. We first extracted and preprocessed the software vulnerabilities using data mining techniques and common vulnerability database. We evaluate the proposed technique using the Common Vulnerability and Exposure (CVE) Database, Common Weakness Enumeration (CWE) Database, National Vulnerability Database (NVD) datasets. Empirical results show that the proposed vulnerability mining algorithm has a remarkable improvement in the vulnerability mining process. The most interesting finding is that, we observed that across all the three projects, recall was around 70{\%} and precision was approximately 60{\%}.},
author = {Li, Xiang and Chen, Jinfu and Lin, Zhechao and Zhang, Lin and Wang, Zibin and Zhou, Minmin and Xie, Wanggen},
booktitle = {Proceedings - 5th International Conference on Advanced Cloud and Big Data, CBD 2017},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - A Mining Approach to Obtain the Software Vulnerability Characteristics.pdf:pdf},
keywords = {Data mining,Essential characteristics,Extraction algorithm,Information security,Software vulnerability},
pages = {296--301},
title = {{A Mining Approach to Obtain the Software Vulnerability Characteristics}},
year = {2017}
}
@inproceedings{Frik,
abstract = {Older adults (65+) are becoming primary users of emerging smart systems, especially in health care. However, these technologies are often not designed for older users and can pose serious privacy and security concerns due to their novelty, complexity, and propensity to collect and communicate vast amounts of sensitive information. Efforts to address such concerns must build on an in-depth understanding of older adults' perceptions and preferences about data privacy and security for these technologies, and accounting for variance in physical and cognitive abilities. In semi-structured interviews with 46 older adults, we identified a range of complex privacy and security attitudes and needs specific to this population, along with common threat models, misconceptions, and mitigation strategies. Our work adds depth to current models of how older adults' limited technical knowledge, experience, and age-related declines in ability amplify vulnerability to certain risks; we found that health, living situation, and finances play a notable role as well. We also found that older adults often experience usability issues or technical uncertainties in mitigating those risks-and that managing privacy and security concerns frequently consists of limiting or avoiding technology use. We recommend educational approaches and usable technical protections that build on seniors' preferences.},
author = {Frik, Alisa and Nurgalieva, Leysan and Bernd, Julia and Lee, Joyce S and Schaub, Florian and Egelman, Serge},
booktitle = {Proceedings of the 15th Symposium on Usable Privacy and Security, SOUPS 2019},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frik et al. - 2019 - Privacy and security threat models and mitigation strategies of older adults.pdf:pdf},
pages = {21--40},
title = {{Privacy and security threat models and mitigation strategies of older adults}},
year = {2019}
}
@inproceedings{Perera2020a,
abstract = {Failure to account for human values in software (e.g., equality and fairness) can result in user dissatisfaction and negative socioeconomic impact. Engineering these values in software, however, requires technical and methodological support throughout the development life cycle. This paper investigates to what extent top Software Engineering (SE) conferences and journals have included research on human values in SE. We investigate the prevalence of human values in recent (2015 2018) publications in these top venues. We classify these publications, based on their relevance to di erent values, against a widely used value structure adopted from the social sciences. Our results show that: (a) only a small proportion of the publications directly consider values, classified as directly relevant publications; (b) for the majority of the values, very few or no directly relevant publications were found; and (c) the prevalence of directly relevant publications was higher in SE conferences compared to SE journals. This paper shares these and other insights that may motivate future research on human values in software engineering.},
author = {Perera, Harsha and Hussain, Waqar and Whittle, Jon and Nurwidyantoro, Arif and Mougouei, Davoud and Shams, Rifat Ara and Oliver, Gillian},
booktitle = {Proceedings - International Conference on Software Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perera et al. - 2020 - A study on the prevalence of human values in software engineering publications 2015 - 2018.pdf:pdf},
keywords = {Human values,Paper classification,Software engineering},
pages = {409--420},
title = {{A study on the prevalence of human values in software engineering publications 2015 - 2018}},
volume = {12},
year = {2020}
}
@article{Yu2021,
abstract = {Recent years have witnessed a sharp increase of malicious apps that steal users' personal information. To address users' concerns about privacy risks and to comply with data protection laws, more and more apps are supplied with privacy policies written in natural language to help users understand an app's privacy practices. However, little is known whether these privacy policies are trustworthy or not. Questionable privacy policies may be prepared by careless app developers or someone with malicious intention. In this paper, we carry out a systematic study on privacy policy by proposing a novel approach to automatically identify five kinds of problems in privacy policy. After tackling several challenging issues, we implement the approach in a system, named PPChecker, and evaluate it with real apps and their privacy policies. The experimental results show that PPChecker can effectively identify questionable privacy policies with high precision. Applying PPChecker to 2,500 popular apps, we find that 1,850 apps (i.e., 74.0 percent) have at least one kind of problems. This study sheds light on the research of improving and regulating apps' privacy policies.},
author = {Yu, Le and Luo, Xiapu and Chen, Jiachi and Zhou, Hao and Zhang, Tao and Chang, Henry and Leung, Hareton K.N.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2021 - PPChecker Towards Accessing the Trustworthiness of Android Apps' Privacy Policies.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {Android apps,privacy policy},
month = {feb},
number = {2},
pages = {221--242},
title = {{PPChecker: Towards Accessing the Trustworthiness of Android Apps' Privacy Policies}},
volume = {47},
year = {2021}
}
@inproceedings{Omoronyia2012,
abstract = {In a dynamic environment where context changes frequently, users' privacy requirements can also change. To satisfy such changing requirements, there is a need for continuous analysis to discover new threats and possible mitigation actions. A frequently changing context can also blur the boundary between public and personal space, making it difficult for users to discover and mitigate emerging privacy threats. This challenge necessitates some degree of self-adaptive privacy management in software applications. This paper presents Caprice - a tool for enabling software engineers to design systems that discover and mitigate contextsensitive privacy threats. The tool uses privacy policies, and associated domain and software behavioural models, to reason over the contexts that threaten privacy. Based on the severity of a discovered threat, adaptation actions are then suggested to the designer. We present the Caprice architecture and demonstrate, through an example, that the tool can enable designers to focus on specific privacy threats that arise from changing context and the plausible category of adaptation action, such as ignoring, preventing, reacting, and terminating interactions that threaten privacy. Copyright 2012 ACM.},
author = {Omoronyia, Inah and Pasquale, Liliana and Salehie, Mazeiar and Cavallaro, Luca and Doherty, Gavin and Nuseibeh, Bashar},
booktitle = {2012 27th IEEE/ACM International Conference on Automated Software Engineering, ASE 2012 - Proceedings},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Omoronyia et al. - 2012 - Caprice A tool for engineering adaptive privacy.pdf:pdf},
keywords = {Adaptive software,Changing context,Privacy,Selective disclosure},
pages = {354--357},
title = {{Caprice: A tool for engineering adaptive privacy}},
year = {2012}
}
@article{Ma2013,
abstract = {Mobility traces of people and vehicles have been collected and published to assist the design and evaluation of mobile networks, such as large-scale urban sensing networks. Although the published traces are often made anonymous in that the true identities of nodes are replaced by random identifiers, the privacy concern remains. This is because in real life, nodes are open to observations in public spaces, or they may voluntarily or inadvertently disclose partial knowledge of their whereabouts. Thus, snapshots of nodes' location information can be learned by interested third parties, e.g., directly through chance/engineered meetings between the nodes and their observers, or indirectly through casual conversations or other information sources about people. In this paper, we investigate how an adversary, when equipped with a small amount of the snapshot information termed as side information, can infer an extended view of the whereabouts of a victim node appearing in an anonymous trace. Our results quantify the loss of victim nodes' privacy as a function of the nodal mobility, the inference strategies of adversaries, and any noise that may appear in the trace or the side information. Generally, our results indicate that the privacy concern is significant in that a relatively small amount of side information is sufficient for the adversary to infer the true identity (either uniquely or with high probability) of a victim in a set of anonymous traces. For instance, an adversary is able to identify the trace of 30{\%}-50{\%} of the victims when she has collected 10 pieces of side information about a victim. {\textcopyright} 1993-2012 IEEE.},
author = {Ma, Chris Y.T. and Yau, David K.Y. and Yip, Nung Kwan and Rao, Nageswara S.V.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2013 - Privacy vulnerability of published anonymous mobility traces.pdf:pdf},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Mobility traces,privacy,security and protection},
number = {3},
pages = {720--733},
title = {{Privacy vulnerability of published anonymous mobility traces}},
volume = {21},
year = {2013}
}
@misc{AppleWatch2019,
author = {{Apple Inc.}},
booktitle = {Apple Support},
title = {{About the security content of watchOS 5.2 - Apple Support}},
url = {https://support.apple.com/en-gb/HT209602},
urldate = {2021-08-30},
year = {2019}
}
@article{Hallgren,
abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
author = {Hallgren, Kevin A.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hallgren - 2012 - Computing inter-rater reliability for observational data An overview and tutorial.pdf:pdf},
journal = {Tutorials in Quantitative Methods for Psychology},
keywords = {behavioral observation,coding,inter-rater agreement,intra-class correlation,kappa,reliability,tutorial},
number = {1},
pages = {23--34},
title = {{Computing inter-rater reliability for observational data: An overview and tutorial.}},
volume = {8},
year = {2012}
}
@inproceedings{Horbe2015a,
abstract = {Federated Identity Management (FIM), while solving important scalability, security and privacy problems of remote entity authentication, introduces new privacy risks. By virtue of sharing identities with many systems, the improved data quality of subjects may increase the possibilities of linking private data sets, moreover, new opportunities for user profiling are being introduced. However, FIM models to mitigate these risks have been proposed. In this paper we elaborate privacy by design requirements for this class of systems, transpose them into specific architectural requirements, and evaluate a number of FIM models with respect to these requirements. The contributions of this paper are a catalog of privacy-related architectural requirements, joining up legal, business and system architecture viewpoints, and the demonstration of concrete FIM models showing how the requirements can be implemented in practice.},
author = {Horbe, Rainer and Hotzendorfer, Walter},
booktitle = {Proceedings - 2015 IEEE Security and Privacy Workshops, SPW 2015},
keywords = {Data protection law,Federated identity management,Identity management,Limited linkability,Limited observability,Privacy,Privacy by design,Security},
pages = {167--174},
title = {{Privacy by design in federated identity management}},
year = {2015}
}
@misc{SNIA2021,
author = {SNIA},
title = {{What is Data Privacy?}},
url = {https://www.snia.org/education/what-is-data-privacy},
urldate = {2021-08-25},
year = {2021}
}
@inproceedings{Scholz2015,
author = {Scholz, Lauren Henry},
booktitle = {Cardozo Law Review de Novo, 2015},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scholz - 2015 - Information Privacy and Data Security.pdf:pdf},
keywords = {Federal Trade Commission,Information Privacy and Data Security,Lauren Henry Scholz,SSRN,breach notification,chief privacy officers,consumer protection,cybersecurity,data breach,data protection,data security,new governance,organizational fields,privacy,professionalization,regulation,security breach},
title = {{Information Privacy and Data Security}},
url = {https://papers.ssrn.com/abstract=2600495},
year = {2015}
}
@article{Wuyts2014a,
abstract = {Privacy is a key issue in today's society. Software systems handle more and more sensitive information concerning citizens. It is important that such systems are privacy-friendly by design. In previous work, we proposed a privacy threat analysis methodology, named LINDDUN. The methodology supports requirements engineers and software architects in identifying privacy weaknesses in the system they contribute to developing. As this is a fairly new technique, its results when applied in realistic scenarios are yet unknown. This paper presents a series of three empirical studies that thoroughly evaluate LINDDUN from a multi-faceted perspective. Our assessment characterizes the correctness and completeness of the analysis results produced by LINDDUN, as well as the productivity associated with executing the methodology. We also look into aspects such as the ease of use and reliability of LINDDUN. The results are encouraging, overall. However, some areas for further improvement have been identified as a result of this empirical inquiry. {\textcopyright} 2014 Elsevier Inc.},
author = {Wuyts, Kim and Scandariato, Riccardo and Joosen, Wouter},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wuyts, Scandariato, Joosen - 2014 - Empirical evaluation of a privacy-focused threat modeling methodology(2).pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Empirical study,Privacy,Threats},
pages = {122--138},
title = {{Empirical evaluation of a privacy-focused threat modeling methodology}},
volume = {96},
year = {2014}
}
@inproceedings{Hasan2020,
abstract = {Photographs taken in public places often contain bystanders - people who are not the main subject of a photo. These photos, when shared online, can reach a large number of viewers and potentially undermine the bystanders' privacy. Furthermore, recent developments in computer vision and machine learning can be used by online platforms to identify and track individuals. To combat this problem, researchers have proposed technical solutions that require bystanders to be proactive and use specific devices or applications to broadcast their privacy policy and identifying information to locate them in an image.We explore the prospect of a different approach - identifying bystanders solely based on the visual information present in an image. Through an online user study, we catalog the rationale humans use to classify subjects and bystanders in an image, and systematically validate a set of intuitive concepts (such as intentionally posing for a photo) that can be used to automatically identify bystanders. Using image data, we infer those concepts and then use them to train several classifier models. We extensively evaluate the models and compare them with human raters. On our initial dataset, with a 10-fold cross validation, our best model achieves a mean detection accuracy of 93{\%} for images when human raters have 100{\%} agreement on the class label and 80{\%} when the agreement is only 67{\%}. We validate this model on a completely different dataset and achieve similar results, demonstrating that our model generalizes well.},
author = {Hasan, Rakibul and Crandall, David and Fritz, Mario and Kapadia, Apu},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hasan et al. - 2020 - Automatically detecting bystanders in photos to reduce privacy risks.pdf:pdf},
keywords = {Bystanders,Computer vision,Machine learning,Photos,Privacy},
pages = {318--335},
title = {{Automatically detecting bystanders in photos to reduce privacy risks}},
volume = {2020-May},
year = {2020}
}
@inproceedings{Jensen2009,
abstract = {Healthcare information systems are currently being migrated from paper based journals to fully digitalised information platforms. Protecting patient privacy is thus becoming an increasingly complex task, where several national and international legal requirements must be met. These legal requirements present only high-level goals for privacy protection, leaving the details of security requirements engineering to the developers of electronic healthcare systems. Our objective has been to map legal requirements for sensitive personal information to a set of reusable technical information security requirements. This paper presents examples of such requirements extracted from legislation applicable to the healthcare domain. {\textcopyright} 2009 IEEE.},
author = {Jensen, Jostein and To{\o}ndel, Inger Anne and Jaatun, Martin Gilje and Meland, Per H{\aa}kon and Andresen, Herbj{\o}rn},
booktitle = {Proceedings - International Conference on Availability, Reliability and Security, ARES 2009},
doi = {10.1109/ARES.2009.107},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jensen et al. - 2009 - Reusable security requirements for healthcare applications.pdf:pdf},
isbn = {9780769535647},
pages = {380--385},
title = {{Reusable security requirements for healthcare applications}},
year = {2009}
}
@inproceedings{Figueiredo2017,
abstract = {With the rise of sensors such as Microsoft Kinect, gesture-based interfaces have become practical. However, to recognize such gestures, applications need access to users' depth and video, exposing sensitive data about individuals and their environment. Prepose, a domain-specific language for building gesture recognizers, combined with a system architecture that protects privacy, security, and reliability with untrusted applications, addresses these threats.},
author = {Figueiredo, Lucas Silva and Molnar, David and Veanes, Margus and Livshits, Benjamin},
booktitle = {IEEE Security and Privacy},
number = {2},
pages = {14--23},
title = {{Prepose: Privacy, security, and reliability for gesture-based programming}},
volume = {15},
year = {2017}
}
@inproceedings{Reinheimer2020d,
abstract = {According to the United States Department of Justice, every 73 seconds, an American is sexually assaulted. However, sexual assault is under-reported. Globally, 95{\%} of sexual assault cases are unreported, and at most, 5 out of every 1,000 perpetrators end up in prison. Online anonymous third-party reporting systems (O-TPRSs) are being developed to encourage reporting of sexual assaults and to apprehend serial offenders. This paper reports survivors' concerns with trusting and using an O-TPRS. We conducted focus groups and interviews with 35 participants who are sexual assault survivors, support workers, or both. We asked questions related to participants' concerns with trusting an O-TPRS. Our results suggest that participants had technological and emotional concerns that are related to survivors' security and privacy. We provide insights into the challenges of designing O-TPRSs to increase the reporting of sexual assault.},
author = {Obada-Obieh, Borke and Spagnolo, Lucrezia and Beznosov, Konstantin},
booktitle = {Proceedings of the 16th Symposium on Usable Privacy and Security, SOUPS 2020},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Obada-Obieh, Spagnolo, Beznosov - 2020 - Towards understanding privacy and trust in online reporting of sexual assault.pdf:pdf},
pages = {145--164},
title = {{Towards understanding privacy and trust in online reporting of sexual assault}},
year = {2020}
}
@inproceedings{Lebeck2018,
abstract = {Immersive augmented reality (AR) technologies are becoming a reality. Prior works have identified security and privacy risks raised by these technologies, primarily considering individual users or AR devices. However, we make two key observations: (1) users will not always use AR in isolation, but also in ecosystems of other users, and (2) since immersive AR devices have only recently become available, the risks of AR have been largely hypothetical to date. To provide a foundation for understanding and addressing the security and privacy challenges of emerging AR technologies, grounded in the experiences of real users, we conduct a qualitative lab study with an immersive AR headset, the Microsoft HoloLens. We conduct our study in pairs - 22 participants across 11 pairs - wherein participants engage in paired and individual (but physically co-located) HoloLens activities. Through semi-structured interviews, we explore participants' security, privacy, and other concerns, raising key findings. For example, we find that despite the HoloLens's limitations, participants were easily immersed, treating virtual objects as real (e.g., stepping around them for fear of tripping). We also uncover numerous security, privacy, and safety concerns unique to AR (e.g., deceptive virtual objects misleading users about the real world), and a need for access control among users to manage shared physical spaces and virtual content embedded in those spaces. Our findings give us the opportunity to identify broader lessons and key challenges to inform the design of emerging single-and multi-user AR technologies.},
author = {Lebeck, Kiron and Ruth, Kimberly and Kohno, Tadayoshi and Roesner, Franziska},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {augmented reality,multi user interaction,privacy,security,user studies},
pages = {392--408},
title = {{Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users}},
volume = {2018-May},
year = {2018}
}
@inproceedings{Petersen2015,
abstract = {Context Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines. Objective To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. Method We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). Results In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. Conclusion The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
author = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
booktitle = {Information and Software Technology},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Petersen, Vakkalanka, Kuzniarz - 2015 - Guidelines for conducting systematic mapping studies in software engineering An update.pdf:pdf},
keywords = {Guidelines,Software engineering,Systematic mapping studies},
pages = {1--18},
title = {{Guidelines for conducting systematic mapping studies in software engineering: An update}},
volume = {64},
year = {2015}
}
@inproceedings{Liu2012b,
abstract = {Software vulnerabilities are the root cause of computer security problem. How people can quickly discover vulnerabilities existing in a certain software has always been the focus of information security field. This paper has done research on software vulnerability techniques, including static analysis, Fuzzing, penetration testing. Besides, the authors also take vulnerability discovery models as an example of software vulnerability analysis methods which go hand in hand with vulnerability discovery techniques. The ending part of the paper analyses the advantages and disadvantages of each technique introduced here and talks about the future direction of this field. {\textcopyright} 2012 IEEE.},
author = {Liu, Bingchang and Shi, Liang and Cai, Zhuhua and Li, Min},
booktitle = {Proceedings - 2012 4th International Conference on Multimedia and Security, MINES 2012},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2012 - Software vulnerability discovery techniques A survey.pdf:pdf},
keywords = {Fuzzing,Penetration testing,Software static analysis,Vulnerability,Vulnerability discovery model},
pages = {152--156},
title = {{Software vulnerability discovery techniques: A survey}},
year = {2012}
}
@inproceedings{Massey2013,
abstract = {Businesses and organizations in jurisdictions around the world are required by law to provide their customers and users with information about their business practices in the form of policy documents. Requirements engineers analyze these documents as sources of requirements, but this analysis is a time-consuming and mostly manual process. Moreover, policy documents contain legalese and present readability challenges to requirements engineers seeking to analyze them. In this paper, we perform a large-scale analysis of 2,061 policy documents, including policy documents from the Google Top 1000 most visited websites and the Fortune 500 companies, for three purposes: (1) to assess the readability of these policy documents for requirements engineers; (2) to determine if automated text mining can indicate whether a policy document contains requirements expressed as either privacy protections or vulnerabilities; and (3) to establish the generalizability of prior work in the identification of privacy protections and vulnerabilities from privacy policies to other policy documents. Our results suggest that this requirements analysis technique, developed on a small set of policy documents in two domains, may generalize to other domains. {\textcopyright} 2013 IEEE.},
author = {Massey, Aaron K. and Eisenstein, Jacob and Anton, Annie I. and Swire, Peter P.},
booktitle = {2013 21st IEEE International Requirements Engineering Conference, RE 2013 - Proceedings},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Massey et al. - 2013 - Automated text mining for requirements analysis of policy documents.pdf:pdf},
pages = {4--13},
title = {{Automated text mining for requirements analysis of policy documents}},
year = {2013}
}
@inproceedings{Valls2009,
abstract = {Sequences of categorical data are in common use to represent sequences of events. In order to transfer such data to third parties for their analysis, masking methods can be applied to satisfy privacy laws and avoid the disclosure of sensitive information. Masking methods distort the data so that privacy is kept at the expenses of some information loss. Microaggregation is one of the existing masking methods. In microaggregation small clusters are automatically built and the values of the members of a cluster are substituted by the values of the prototype of that cluster. Due to the fact that microaggregation is an NP-hard problem, heuristic approaches have been developed. Existing methods are mainly devoted to numerical and categorical data. The extension of these methods to sequences of categorical data requires the definition of special algorithms for clustering and prototyping. Artificial Intelligence offers techniques and tools that are appropriate for symbolic data. As in our context the sequences are defined in terms of categorical (symbolic) values, such AI techniques are of special relevance. In this paper, we will use them to propose a new method for generating the prototype of a small group of sequences of categorical values. These results can later be used in e.g. microaggregation. {\textcopyright} 2009 IEEE.},
author = {Valls, Aida and G{\'{o}}mez-Alonso, Cristina and Torra, Vicen{\c{c}}},
booktitle = {Proceedings - International Conference on Availability, Reliability and Security, ARES 2009},
doi = {10.1109/ARES.2009.55},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Valls, G{\'{o}}mez-Alonso, Torra - 2009 - Generation of prototypes for masking sequences of events.pdf:pdf},
isbn = {9780769535647},
pages = {947--952},
title = {{Generation of prototypes for masking sequences of events}},
year = {2009}
}
@article{Bhatia2019a,
abstract = {Companies that collect personal information online often maintain privacy policies that are required to accurately reflect their data practices and privacy goals. To be comprehensive and flexible for future practices, policies contain ambiguity that summarizes practices over multiple types of products and business contexts. Ambiguity in data practice descriptions undermines policies as an effective way to communicate system design choices to users and as a reliable regulatory mechanism. In this paper, we report an investigation to identify incompleteness by representing data practice descriptions as semantic frames. The approach is a grounded analysis to discover which semantic roles corresponding to a data action are needed to construct complete data practice descriptions. Our results include 698 data action instances obtained from 949 manually annotated statements across 15 privacy policies and three domains: health, news and shopping. Therein, we identified 2316 instances of 17 types of semantic roles and found that the distribution of semantic roles across the three domains was similar. Incomplete data practice descriptions undermine user comprehension and can affect the user's perceived privacy risk, which we measure using factorial vignette surveys. We observed that user risk perception decreases when two roles are present in a statement: the condition under which a data action is performed, and the purpose for which the user's information is used.},
author = {Bhatia, Jaspreet and Evans, Morgan C and Breaux, Travis D},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatia, Evans, Breaux - 2019 - Identifying incompleteness in privacy policy goals using semantic frames(2).pdf:pdf},
journal = {Requirements Engineering},
keywords = {Natural language processing,Privacy,Privacy risk,Semantic frames,Semantic roles},
number = {3},
pages = {291--313},
title = {{Identifying incompleteness in privacy policy goals using semantic frames}},
volume = {24},
year = {2019}
}
@inproceedings{Shin2006,
abstract = {Privacy has been a central concern of ubiquitous (pervasive) computing. Although the boundary between privacy and publicity dynamically moves depending on the context in which the issue is considered, access control, which is one of the most fundamental functionality constituting ubiquitous computing, is required to support perfect privacy, that is, anonymity and unlinkability. This paper presents a concrete protocol for anonymous access control that supports compliance to the distributed trust management model introduced by Blaze et al, efficiency for continual verification and provable security. In addition, the protocol is based on a practical trust model that models the heterogeneous structure of trust in the real world. The model defines a service provider, a service appliance, users and a device that users carry or wear as independent players, and further assumes that trust between them is independently established only based on their arbitrary mutual agreements. {\textcopyright} 2006 IEEE.},
author = {Shin, Kilho and Yasuda, Hiroshi},
booktitle = {Proceedings - First International Conference on Availability, Reliability and Security, ARES 2006},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shin, Yasuda - 2006 - Provably secure anonymous access control for heterogeneous trusts.pdf:pdf},
pages = {24--32},
title = {{Provably secure anonymous access control for heterogeneous trusts}},
volume = {2006},
year = {2006}
}
@inproceedings{Bhaskar2007,
abstract = {Privacy appears as a major issue for pervasive computing applications. Several models have been proposed to address privacy challenges. Successful design requires awareness of the technology's users and that their desires and concerns are understood. This is difficult as few empirical researches exist about potential pervasive users that designers can use. Complicating design further is the fact that pervasive systems are typically embedded or invisible, making it difficult for users to know when these devices are present and collecting data. As users have a limited understanding of the technology several privacy, design, and safety issues are raised. This paper discusses how privacy might be preserved in a pervasive computing environment. It presents some research developments in these areas to address privacy concerns. Open issues and challenges are also examined. {\textcopyright} 2007 IEEE.},
author = {Bhaskar, Pankaj and Ahamed, Sheikh I.},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhaskar, Ahamed - 2007 - Privacy in pervasive computing and open issues.pdf:pdf},
isbn = {0769527752},
keywords = {Location privacy,Pervasive computing,Privacy,Security,Trust},
pages = {147--154},
title = {{Privacy in pervasive computing and open issues}},
year = {2007}
}
@inproceedings{Galhardo2020,
abstract = {In this work, we provide a metric to calculate the most significant software security weaknesses as defined by an aggregate metric of the frequency, exploitability, and impact of related vulnerabilities. The Common Weakness Enumeration (CWE) is a well-known and used list of software security weaknesses. The CWE community publishes such an aggregate metric to calculate the Most Dangerous Software Errors. However, we find that the published equation highly biases frequency and almost ignores exploitability and impact in generating top lists of varying sizes. This is due to the differences in the distributions of the component metric values. To mitigate this, we linearize the frequency distribution using a double log function. We then propose a variety of other improvements, provide top lists of the most significant CWEs for 2019, provide an analysis of the identified software security weaknesses, and compare them against previously published top lists.},
author = {Galhardo, Carlos Cardoso and Mell, Peter and Bojanova, Irena and Gueye, Assane},
booktitle = {ACM International Conference Proceeding Series},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Galhardo et al. - 2020 - Measurements of the Most Significant Software Security Weaknesses.pdf:pdf},
keywords = {Security,Severity,Software Flaw,Weakness},
pages = {154--164},
title = {{Measurements of the Most Significant Software Security Weaknesses}},
volume = {11},
year = {2020}
}
@inproceedings{Omoronyia2013a,
abstract = {Applications that continuously gather and disclose personal information about users are increasingly common. While disclosing this information may be essential for these applications to function, it may also raise privacy concerns. Partly, this is due to frequently changing context that introduces new privacy threats, and makes it difficult to continuously satisfy privacy requirements. To address this problem, applications may need to adapt in order to manage changing privacy concerns. Thus, we propose a framework that exploits the notion of privacy awareness requirements to identify runtime privacy properties to satisfy. These properties are used to support disclosure decision making by applications. Our evaluations suggest that applications that fail to satisfy privacy awareness requirements cannot regulate users' information disclosure. We also observe that the satisfaction of privacy awareness requirements is useful to users aiming to minimise exposure to privacy threats, and to users aiming to maximise functional benefits amidst increasing threat severity. {\textcopyright} 2013 IEEE.},
author = {Omoronyia, Inah and Cavallaro, Luca and Salehie, Mazeiar and Pasquale, Liliana and Nuseibeh, Bashar},
booktitle = {Proceedings - International Conference on Software Engineering},
keywords = {Privacy,adaptation,selective disclosure,utility},
pages = {632--641},
title = {{Engineering adaptive privacy: On the role of privacy awareness requirements}},
year = {2013}
}
@article{Bambauer2013,
author = {Bambauer, Derek E},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bambauer - 2013 - Privacy Versus Security.pdf:pdf},
journal = {Journal of Criminal Law and Criminology},
number = {3},
title = {{Privacy Versus Security}},
url = {https://scholarlycommons.law.northwestern.edu/jclc/vol103/iss3/2},
volume = {103},
year = {2013}
}
@misc{Wagner2018b,
abstract = {The goal of privacy metrics is tomeasure the degree of privacy enjoyed by users in a system and the amount of protection offered by privacy-enhancing technologies. In this way, privacy metrics contribute to improving user privacy in the digital world. The diversity and complexity of privacy metrics in the literature make an informed choice of metrics challenging. As a result, instead of using existing metrics, new metrics are proposed frequently, and privacy studies are often incomparable. In this survey, we alleviate these problems by structuring the landscape of privacy metrics. To this end, we explain and discuss a selection of over 80 privacy metrics and introduce categorizations based on the aspect of privacy they measure, their required inputs, and the type of data that needs protection. In addition, we present a method on how to choose privacy metrics based on nine questions that help identify the right privacy metrics for a given scenario, and highlight topics where additional work on privacy metrics is needed. Our survey spans multiple privacy domains and can be understood as a general framework for privacy measurement.},
author = {Wagner, Isabel and Eckhoff, David},
booktitle = {ACM Computing Surveys},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wagner, Eckhoff - 2018 - Technical privacy metrics A systematic survey(3).pdf:pdf},
keywords = {Measuring privacy,Privacy metrics},
number = {3},
title = {{Technical privacy metrics: A systematic survey}},
volume = {51},
year = {2018}
}
@inproceedings{Ayala-Rivera2018,
abstract = {The General Data Protection Regulation (GDPR) aims to protect personal data of EU residents and can impose severe sanctions for non-compliance. Organizations are currently implementing various measures to ensure their software systems fulfill GDPR obligations such as identifying a legal basis for data processing or enforcing data anonymization. However, as regulations are formulated vaguely, it is difficult for practitioners to extract and operationalize legal requirements from the GDPR. This paper aims to help organizations understand the data protection obligations imposed by the GDPR and identify measures to ensure compliance. To achieve this goal, we propose GuideMe, a 6-step systematic approach that supports elicitation of solution requirements that link GDPR data protection obligations with the privacy controls that fulfill these obligations and that should be implemented in an organization's software system. We illustrate and evaluate our approach using an example of a university information system. Our results demonstrate that the solution requirements elicited using our approach are aligned with the recommendations of privacy experts and are expressed correctly.},
author = {Ayala-Rivera, Vanessa and Pasquale, Liliana},
booktitle = {Proceedings - 2018 IEEE 26th International Requirements Engineering Conference, RE 2018},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayala-Rivera, Pasquale - 2018 - The grace period has ended An approach to operationalize GDPR requirements.pdf:pdf},
keywords = {Compliance,GDPR,Privacy,Requirements,Solution requirements},
mendeley-tags = {GDPR,Solution requirements},
pages = {136--146},
title = {{The grace period has ended: An approach to operationalize GDPR requirements}},
year = {2018}
}
@misc{GLBA,
author = {{United State Congress}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/United State Congress - 1999 - GRAMM-LEACH-BLILEY ACT.pdf:pdf},
title = {{GRAMM-LEACH-BLILEY ACT}},
url = {https://www.govinfo.gov/content/pkg/PLAW-106publ102/pdf/PLAW-106publ102.pdf},
year = {1999}
}
@misc{CCPA,
author = {{California State Legislature}},
booktitle = {California Civil Code},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/California State Legislature - 2018 - California Consumer Privacy Act of 2018.pdf:pdf},
title = {{California Consumer Privacy Act of 2018}},
year = {2018}
}
@article{Siewe2016a,
abstract = {Ubiquitous computing systems collect and share a great deal of information upon the users and their environment; including private or highly sensitive personal information. Unless users are confident enough that their privacy is protected, many will be deterred from using such systems. This paper proposes a privacy type system that controls the behaviour of concurrent, context-aware and mobile processes to ensure that private information is not accidentally disclosed. We prove the subject reduction property and the soundness of the proposed type system; which guarantee that a well-typed process cannot accidentally disclose private information. We demonstrate the pragmatics of our approach with a case study.},
author = {Siewe, Fran{\c{c}}ois and Yang, Hongji},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Siewe, Yang - 2016 - Privacy protection by typing in ubiquitous computing systems.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Pervasive systems,Privacy,Security,Simulation,Type system,Type-checking,Ubiquitous computing},
pages = {133--153},
title = {{Privacy protection by typing in ubiquitous computing systems}},
volume = {120},
year = {2016}
}
@inproceedings{Huang2011c,
abstract = {The protection of patients' health information is a very important issue in the information age. Health Insurance Portability and Accountability Act (HIPAA) of privacy and security regulations are two crucial provisions in the protection of healthcare privacy, especially electronic medical information. For the quality and efficiency of the electronic services, it is necessary to construct better performance for the user and the trusted party. Based on elliptic curve cryptography (ECC) and complying with HIPAA regulations, this article presents an efficient key management scheme to facilitate inter-operations among the applied cryptographic mechanisms. In addition, the proposed scheme can achieve the complete functionality which includes: (1) a dictionary of key tables is not required for users and other units; (2) users can freely choose their own passwords; (3) users can freely update their passwords after the registration phase; (4) the computational cost is very low for users and the trusted center or server; (5) users are able to access their individual medical information through the authorization process; (6) case of consent exceptions intended to facilitate emergency applications or other possible exceptions can also be dealt with easier. {\textcopyright} 2010 Elsevier Inc.},
author = {Huang, Hui Feng and Liu, Kuo Ching},
booktitle = {Journal of Systems and Software},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Liu - 2011 - Efficient key management for preserving HIPAA regulations.pdf:pdf},
keywords = {Cryptography,HIPAA,Privacy,Protected health information,Security},
number = {1},
pages = {113--119},
title = {{Efficient key management for preserving HIPAA regulations}},
volume = {84},
year = {2011}
}
@inproceedings{Riedl2007,
abstract = {As aging and very expensive programs put more pressure on health and social care systems, an increase in the need for electronic healthcare records can be observed, because they promise massive savings and better clinical quality. However, patients and commissioners for data protection have legitimate concerns about the privacy and confidentiality of the stored data. Although the concept of pseudonymization allows an association with a patient only under specified and controlled circumstances, existing approaches have major vulnerabilities. This paper provides a new architecture for the pseudonymization of medical data that combines primary and secondary use in one system and thus provides a solution to vulnerabilities of existing approaches. {\textcopyright} 2007 IEEE.},
author = {Riedl, Bernhard and Neubauer, Thomas and Goluch, Gernot and Boehm, Oswald and Reinauer, Gert and Krumboeck, Alexander},
booktitle = {Proceedings - Second International Conference on Availability, Reliability and Security, ARES 2007},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Riedl et al. - 2007 - A secure architecture for the pseudonymization of medical data.pdf:pdf},
pages = {318--324},
title = {{A secure architecture for the pseudonymization of medical data}},
year = {2007}
}
@misc{Statista,
author = {Statista},
title = {{Annual number of data breaches and exposed records in the United States from 2005 to 2020}},
url = {https://bit.ly/statistaUS2022},
urldate = {2021-08-25},
year = {2021}
}
@article{Zein2016,
abstract = {The importance of mobile application specific testing techniques and methods has been attracting much attention of software engineers over the past few years. This is due to the fact that mobile applications are different than traditional web and desktop applications, and more and more they are moving to being used in critical domains. Mobile applications require a different approach to application quality and dependability and require an effective testing approach to build high quality and more reliable software. We performed a systematic mapping study to categorize and to structure the research evidence that has been published in the area of mobile application testing techniques and challenges that they have reported. Seventy nine (79) empirical studies are mapped to a classification schema. Several research gaps are identified and specific key testing issues for practitioners are identified: there is a need for eliciting testing requirements early during development process; the need to conduct research in real-world development environments; specific testing techniques targeting application life-cycle conformance and mobile services testing; and comparative studies for security and usability testing.},
author = {Zein, Samer and Salleh, Norsaremah and Grundy, John},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zein, Salleh, Grundy - 2016 - A systematic mapping study of mobile application testing techniques.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Mobile application testing,Software testing,Systematic mapping},
pages = {334--356},
title = {{A systematic mapping study of mobile application testing techniques}},
volume = {117},
year = {2016}
}
@article{Iqbal2009,
abstract = {As portable devices have become a part of our everyday life, more people are unknowingly participating in a pervasive computing environment. People engage with not a single device for a specific purpose but many devices interacting with each other in the course of ordinary activity. With such prevalence of pervasive technology, the interaction between portable devices needs to be continuous and imperceptible to device users. Pervasive computing requires a small, scalable and robust network which relies heavily on the middleware to resolve communication and security issues. In this paper, we present the design and implementation of S-MARKS which incorporates device validation, resource discovery and a privacy module. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Ahamed, Sheikh Iqbal and Li, Haifeng and Talukder, Nilothpal and Monjur, Mehrab and Hasan, Chowdhury Sharif},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahamed et al. - 2009 - Design and implementation of S-MARKS A secure middleware for pervasive computing applications.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Device validation and resource discovery,Pervasive computing,Secure middleware},
number = {10},
pages = {1657--1677},
title = {{Design and implementation of S-MARKS: A secure middleware for pervasive computing applications}},
url = {https://dl.acm.org/doi/abs/10.1016/j.jss.2009.03.020},
volume = {82},
year = {2009}
}
@article{HoaTSE21,
abstract = {Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.},
author = {Dam, Hoa Khanh and Tran, Truyen and Pham, Trang and Ng, Shien Wee and Grundy, John and Ghose, Aditya},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dam et al. - 2021 - Automatic Feature Learning for Predicting Vulnerable Software Components.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software vulnerability prediction,empirical software engineering,mining software engineering repositories},
number = {1},
pages = {67--85},
title = {{Automatic Feature Learning for Predicting Vulnerable Software Components}},
volume = {47},
year = {2021}
}
@article{Sicari2012a,
abstract = {End-to-end data aggregation, without degrading sensing accuracy, is a very relevant issue in wireless sensor networks (WSN) that can prevent network congestion to occur. Moreover, privacy management requires that anonymity and data integrity are preserved in such networks. Unfortunately, no integrated solutions have been proposed so far, able to tackle both issues in a unified and general environment. To bridge this gap, in this paper we present an approach for dynamic secure end-to-end data aggregation with privacy function, named DyDAP. It has been designed starting from a UML model that encompasses the most important building blocks of a privacy-aware WSN, including aggregation policies. Furthermore, it introduces an original aggregation algorithm that, using a discrete-time control loop, is able to dynamically handle in-network data fusion to reduce the communication load. The performance of the proposed scheme has been verified using computer simulations, showing that DyDAP avoids network congestion and therefore improves WSN estimation accuracy while, at the same time, guaranteeing anonymity and data integrity. {\textcopyright} 2011 Elsevier Inc.},
author = {Sicari, Sabrina and Grieco, Luigi Alfredo and Boggia, Gennaro and Coen-Porisini, Alberto},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sicari et al. - 2012 - DyDAP A dynamic data aggregation scheme for privacy aware wireless sensor networks.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Anonymity,Congestion control,End-to-end data aggregation,Privacy,Wireless sensor networks},
number = {1},
pages = {152--166},
title = {{DyDAP: A dynamic data aggregation scheme for privacy aware wireless sensor networks}},
volume = {85},
year = {2012}
}
@inproceedings{Fan2009a,
abstract = {Due to the flush development of academic research, a great deal research results have been published in conference proceedings and journals. However, these articles need to be inspected by some professionals in specific fields. It is the most important that it must keep fair during the entire process of reviewing. However, the privacy of reviewers will be leaked out because that the reviewers must sign their comments on the reviewed papers. The leakage of the reviewers' privacy will affect the fairness of paper reviewing. In addition, the authors need to show their names to the editor of conference proceedings or journals such that it may also make the inspecting results unfair. Unfortunately, the solutions proposed in the literature cannot cope with the problems of fairness well. Therefore, in order to eliminate the drawbacks of the previous schemes, we will deeply analyze the paper review procedure to find the possible reasons that bring about these unfair results. Furthermore, we will present a generic idea, which is independent of the underlying cryptographic components, to achieve the fairness property and other requirements in a paper review scheme. {\textcopyright} 2009 IEEE.},
author = {Fan, Chun I. and Chen, Ming Te and Chen, Lung Hsien},
booktitle = {Proceedings - International Conference on Availability, Reliability and Security, ARES 2009},
doi = {10.1109/ARES.2009.30},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan, Chen, Chen - 2009 - Truly anonymous paper submission and review scheme.pdf:pdf},
isbn = {9780769535647},
keywords = {Anonymous channels,Anonymous paper review,Anonymous paper submission,Blind signatures,Cryptography,Information security,Universal designated-verifier signatures (UDVS)},
pages = {960--965},
title = {{Truly anonymous paper submission and review scheme}},
year = {2009}
}
@article{Kitchenham2007a,
abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
author = {Kitchenham, Barbara},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kitchenham - 2007 - Guidelines for performing systematic literature reviews in software engineering(2).pdf:pdf},
journal = {Technical report, Ver. 2.3 EBSE Technical Report. EBSE},
title = {{Guidelines for performing systematic literature reviews in software engineering}},
year = {2007}
}
@inproceedings{Kroger2020,
abstract = {EU data protection laws grant consumers the right to access the personal data that companies hold about them. In a first-of-its-kind longitudinal study, we examine how service providers have complied with subject access requests over four years. In three iterations between 2015 and 2019, we sent subject access requests to vendors of 225 mobile apps popular in Germany. Throughout the iterations, 19 to 26{\%} of the vendors were unreachable or did not reply at all. Our subject access requests were fulfilled in 15 to 53{\%} of the cases, with an unexpected decline between the GDPR enforcement date and the end of our study. The remaining responses exhibit a long list of shortcomings, including severe violations of information security and data protection principles. Some responses even contained deceptive and misleading statements (7 to 13{\%}). Further, 9{\%} of the apps were discontinued and 27{\%} of the user accounts vanished during our study, mostly without proper notification about the consequences for our personal data. While we observe improvements for selected aspects over time, the results indicate that subject access request handling will be unsatisfactory as long as vendors accept such requests via email and process them manually.},
author = {Kr{\"{o}}ger, Jacob Leon and Lindemann, Jens and Herrmann, Dominik},
booktitle = {ARES '20: Proceedings of the 15th International Conference on Availability, Reliability and Security},
doi = {10.1145/3407023.3407057},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kr{\"{o}}ger, Lindemann, Herrmann - 2020 - How do app vendors respond to subject access requests A longitudinal privacy study on iOS and Andro.pdf:pdf},
isbn = {9781450388337},
issn = {21531633},
keywords = {Compliance,GDPR,Mobile app,Privacy,Smartphone,Subject access request},
pages = {1--10},
publisher = {ACM},
title = {{How do app vendors respond to subject access requests?: A longitudinal privacy study on iOS and Android Apps}},
year = {2020}
}
@article{Castiglione2010a,
abstract = {The Portable Document Format (PDF) was developed by Adobe in the early nineties and today it is the de-facto standard for electronic document exchange. It allows reliable reproductions of published materials on any platform and it is used by many governmental and educational institutions, as well as companies and individuals. PDF documents are also credited with being more secure than other document formats such as Microsoft Compound Document File Format or Rich Text Format. This paper investigates the Portable Document Format and shows that it is not immune from some privacy related issues that affect other popular document formats. From a PDF document, it is possible to retrieve any text or object previously deleted or modified, extract user information and perform some actions that may be used to violate user privacy. There are several applications of such an issue. One of them is relevant to the scientific community and it pertains to the ability to overcome the blind review process of a paper, revealing information related to the anonymous referee (e.g., the IP address of the referee). {\textcopyright} 2010 Elsevier Inc. All rights reserved.},
author = {Castiglione, Aniello and {De Santis}, Alfredo and Soriente, Claudio},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Castiglione, De Santis, Soriente - 2010 - Security and privacy issues in the Portable Document Format.pdf:pdf},
journal = {Journal of Systems and Software},
keywords = {Compound document format,Digital forensics,Digital investigations,Document security,Electronic document,Information forensics,Information leakage,Portable Document Format (PDF),Privacy,Security},
number = {10},
pages = {1813--1822},
title = {{Security and privacy issues in the Portable Document Format}},
volume = {83},
year = {2010}
}
@misc{HumanDynamics,
author = {{Human Dynamics}},
title = {{Human Dynamics Github Repository}},
url = {https://github.com/HumanDynamics},
urldate = {2021-09-04}
}
@article{Lin2020,
abstract = {The constantly increasing number of disclosed security vulnerabilities have become an important concern in the software industry and in the field of cybersecurity, suggesting that the current approaches for vulnerability detection demand further improvement. The booming of the open-source software community has made vast amounts of software code available, which allows machine learning and data mining techniques to exploit abundant patterns within software code. Particularly, the recent breakthrough application of deep learning to speech recognition and machine translation has demonstrated the great potential of neural models' capability of understanding natural languages. This has motivated researchers in the software engineering and cybersecurity communities to apply deep learning for learning and understanding vulnerable code patterns and semantics indicative of the characteristics of vulnerable code. In this survey, we review the current literature adopting deep-learning-/neural-network-based approaches for detecting software vulnerabilities, aiming at investigating how the state-of-the-art research leverages neural techniques for learning and understanding code semantics to facilitate vulnerability discovery. We also identify the challenges in this new field and share our views of potential research directions.},
author = {Lin, Guanjun and Wen, Sheng and Han, Qing Long and Zhang, Jun and Xiang, Yang},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2020 - Software Vulnerability Detection Using Deep Neural Networks A Survey(2).pdf:pdf},
journal = {Proceedings of the IEEE},
keywords = {Cybersecurity,deep neural network (DNN),machine learning (ML),representation learning,software vulnerability},
number = {10},
pages = {1825--1848},
title = {{Software Vulnerability Detection Using Deep Neural Networks: A Survey}},
volume = {108},
year = {2020}
}
@inproceedings{Lebeck2017,
abstract = {Augmented reality (AR) technologies, such as Microsoft's HoloLens head-mounted display and AR-enabled car windshields, are rapidly emerging. AR applications provide users with immersive virtual experiences by capturing input from a user's surroundings and overlaying virtual output on the user's perception of the real world. These applications enable users to interact with and perceive virtual content in fundamentally new ways. However, the immersive nature of AR applications raises serious security and privacy concerns. Prior work has focused primarily on input privacy risks stemming from applications with unrestricted access to sensor data. However, the risks associated with malicious or buggy AR output remain largely unexplored. For example, an AR windshield application could intentionally or accidentally obscure oncoming vehicles or safety-critical output of other AR applications. In this work, we address the fundamental challenge of securing AR output in the face of malicious or buggy applications. We design, prototype, and evaluate Arya, an AR platform that controls application output according to policies specified in a constrained yet expressive policy framework. In doing so, we identify and overcome numerous challenges in securing AR output.},
author = {Lebeck, Kiron and Ruth, Kimberly and Kohno, Tadayoshi and Roesner, Franziska},
booktitle = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Augmented reality,Security},
pages = {320--337},
title = {{Securing Augmented Reality Output}},
year = {2017}
}
